@STRING{AW = {Addison Wesley}}

@STRING{MK = {Morgan Kaufmann Publishers}}

@INBOOK{kraemer:04,
  pages = {643-671},
  title = {Mensch-Computer-Interaktion},
  year = {2004},
  author = {Krämer, Nicole},
  crossref = {mangold:04}
}

@Book{brill:09,
  author    = {{Brill, Manfred}},
  title     = {Virtuelle Realit\"at},
  publisher = {Springer},
  year      = {2009},
}

@BOOK{gibson:87,
  title = {Neuromancer},
  publisher = {Heyne},
  year = {1987},
  author = {Gibson, William}
}


@BOOK{burdea:03,
  title = {Virtual Reality Technology},
  publisher = {Wiley},
  year = {2003},
  author = {{Burdea, Grigore} and {Coiffet, Philippe}}
}

@BOOK{burdea:08,
  title = {Virtual Reality Technology},
  publisher = {IEEE},
  year = {2008},
  author = {{Burdea, Grigore} and {Coiffet, Philippe}}
}

@BOOK{blackman:99,
  title = {Modern Tracking Systems},
  publisher = {Artech House},
  year = {1999},
  author = {{Blackmann,~S.} and {Popoli,~R.}}
}

@BOOK{duden:97,
  title = {Deutsches Universalwörterbuch},
  publisher = {Dudenverlag},
  year = {1997},
  author = {Duden}
}

@Book{tate:04,
  author    = {Tate, Scott},
  title     = {Virtual Reality: A Historical Perspective},
  publisher = {http://ei.cs.vt.edu/~history/Tate.VR.html.},
  year      = {2004},
}

@BOOK{thalmann:08,
  title = {Stepping into Virtual Reality},
  publisher = {Springer},
  year = {2008},
  author = {{Thalmann~D.} and {Gutierrez,~M.} and {Vexo,~F.}}
}

@BOOK{kalawsky:93,
  title = {The Science of Virtual Reality},
  publisher = AW,
  year = {1993},
  author = {Kalawsky, Roy S.}
}

@BOOK{sherman:03,
  title = {Understanding Virtual Reality - Interface, Application, and Design},
  publisher = MK,
  year = {1993},
  author = {{Shermann, William R.} and {Craig, Alan B.}}
}

@BOOK{vince:95,
  title = {Virtual Reality Systems},
  publisher = AW,
  year = {1995},
  author = {Vince, John}
}

@BOOK{heilig:55,
  title = {The Cinema of the Future},
  publisher = {Espacios},
  year = {1955},
  author = {Heilig, Morton}
}

@BOOK{krueger:83,
  title = {Artificial Reality},
  publisher = AW,
  year = {1983},
  author = {Krueger, Myron}
}

@BOOK{rheingold:92,
  title = {Virtuelle Welten. Reisen im Cyberspace},
  publisher = {Rowohlt},
  year = {1992},
  author = {Rheingold, Howard}
}

@Book{din:05,
  author    = {{DIN ISO 33402-2:2005-12}},
  title     = {Körpermaße des Menschen Teil 2 -- Ergonomie},
  year      = {2005},
  publisher = {Beuth},
  doi       = {https://dx.doi.org/10.31030/9655264},
}

@BOOK{geo:07,
  title = {GEO Themenlexikon in 20 Bänden. Band 8 Naturwissenschaft und Technik},
  publisher = {Bibliographisches Institut, Mannheim},
  year = {2007},
  editor = {Gaede, Peter-Matthias}
}

@Book{brockhaus:97,
  author    = {Brockhaus},
  title     = {Die Enzyklopädie. 20., überarbeitete und aktualisierte Auflage},
  year      = {1997},
  editor    = {Brockhaus},
  publisher = {F.A. Brockhaus GmbH Leipzig-Mannheim},
}

@BOOK{hofmann:90,
  title = {Das Stereoskop -- Geschichte der Stereoskopie},
  publisher = {Deutsches Museum M�nchen},
  year = {1990},
  author = {Albrecht Hofmann}
}

@BOOK{mangold:04,
  title = {Lehrbuch der Medienpsychologie},
  publisher = {Hogrefe},
  year = {2004},
  author = {{Mangold, Roland} and {Vorderer, Peter} and {Bente, Gary}}
}

@BOOK{ericson:04,
  title = {Real-Time Collision Detection},
  publisher = MK,
  year = {2004},
  author = {Ericson, Christer}
}

@INPROCEEDINGS{ware:93,
  author = {Colin Ware and Kevin Arthur and Kellogg S. Booth},
  title = {Fish tank virtual reality},
  booktitle = {CHI '93: Proceedings of the INTERACT '93 and CHI '93 conference on
	Human factors in computing systems},
  year = {1993},
  pages = {37--42},
  publisher = {ACM}
}

@ARTICLE{ware:95,
  author = {Colin Ware and Kevin Arthur and Kellogg S. Booth},
  title = {Evaluating {3D} task performance for fish tank virtual worlds},
  journal = {Transactions on Information Systems},
  year = {1995},
  volume = {11},
  pages = {239--265},
  number = {3},
  publisher = {ACM}
}

@ARTICLE{ware:96,
  author = {Colin Ware and Glenn Franck},
  title = {Evaluating stereo and motion cues for visualizing information nets
	in three dimensions},
  journal = {ACM Trans. Graph.},
  year = {1996},
  volume = {15},
  pages = {121--140},
  number = {2},
  publisher = {ACM}
}

@ARTICLE{welch:02,
  author = {{Welch,~G.} and {Foxlin,~E.}},
  title = {Motion Tracking: No Silver Bullet, but a Respectable Arsenal},
  journal = {IEEE Computer Graphics and Applications},
  year = {2002},
  volume = {22},
  pages = {24--38},
  number = {6}
}

@INPROCEEDINGS{ware:05,
  author = {{Ware,~C.} and {Mitchell,~P.}},
  title = {Re-evaluating stereo and motion cues for visualizing graphs in three
	dimensions},
  booktitle = {APGV 05: Proceedings of the 2nd symposium on applied perception in
	graphics and visualization},
  year = {2005},
  pages = {51--58},
  publisher = {ACM}
}

@INPROCEEDINGS{qi:06,
  author = {{Qi,~W.} and {Taylor,~R.} and {Healey,~C.~G.} and {Martens.~J.~B.}},
  title = {A comparison of immersive {HMD}, {Fish Tank VR} and {Fish Tank} with
	haptics displays for volume visualization},
  booktitle = {APGV 06: Proceedings of the 3rd symposium on applied perception in
	graphics and visualization},
  year = {2006},
  pages = {51--58},
  publisher = {ACM}
}

@INPROCEEDINGS{deering:92,
  author = {Deering, Michael},
  title = {High resolution virtual reality},
  booktitle = {SIGGRAPH '92: Proceedings of the 19th annual conference on Computer
	graphics and interactive techniques},
  year = {1992},
  pages = {195--202},
  publisher = {ACM}
}

@INPROCEEDINGS{schmandt:83,
  author = {Schmandt, Christopher},
  title = {Spatial input/display correspondence in a stereoscopic computer graphic
	work station},
  booktitle = {SIGGRAPH '83: Proceedings of the 10th annual conference on Computer
	graphics and interactive techniques},
  year = {1983},
  pages = {253--261},
  publisher = {ACM}
}

@INPROCEEDINGS{ellis:89,
  author = {{Ellis,~S.} and Grunwald,~A.},
  title = {Visions of visualization aids: design philosophy and observations},
  booktitle = {Proceedings of the SPIE OE/LASE '89, Symposium on three-dimensional
	visualization of scientific data},
  year = {1989},
  pages = {220--227},
  publisher = {SPIE}
}

@INPROCEEDINGS{roese:79,
  author = {{Roese,~J.~A.} and {McCleary,~L.~E-}},
  title = {Stereoscopic computer graphics for simulation and modeling},
  booktitle = {SIGGRAPH '79: Proceedings of the 6th annual conference on Computer
	graphics and interactive techniques},
  year = {1979},
  pages = {41--47},
  publisher = {ACM}
}

@INPROCEEDINGS{mulder:03,
  author = {Jurriaan D. Mulder and Jack Jansen and Arjen van Rhijn},
  title = {An affordable optical head tracking system for desktop VR/AR systems},
  booktitle = {EGVE '03: Proceedings of the workshop on Virtual environments 2003},
  year = {2003},
  pages = {215--223},
  publisher = {ACM}
}

@INPROCEEDINGS{cruzneira:93,
  author = {{Cruz-Neira,~C.} and {Sandin,~D.J.} and {DeFanti,~T.~A.}},
  title = {Surround-screen projection-based virtual reality: the design and
	implementation of the {CAVE}},
  booktitle = {SIGGRAPH '93: Proceedings of the 20th annual conference on Computer
	graphics and interactive techniques},
  year = {1993},
  pages = {135--142},
  publisher = {ACM}
}

@InProceedings{sutherland:65,
  author    = {{Sutherland, Ivan E.}},
  booktitle = {Proceedings of the IFIP Congress},
  title     = {The Ultimate Display},
  pages     = {506--508},
  volume    = {2},
  year      = {1965},
}

@INPROCEEDINGS{azuma:95,
  author = {Azuma, Ronald},
  title = {A survey of augmented reality},
  booktitle = {SIGGRAPH '95: Proceedings of the 20th annual conference on Computer
	graphics and interactive techniques. Course Notes: Developing Advanced
	Virtual Reality Applications},
  year = {1995},
  pages = {1--38.}
}

@Article{azuma:01,
  author  = {{Azuma, Ronald} and {Baillot, Yohan} and {Behringer, Reinhold} and {Feiner, Steven} and {Julier, Simon} and , {BacIntyre, Blair}},
  title   = {Recent Advances in Augmented Reality},
  number  = {6},
  pages   = {34--47},
  volume  = {21},
  journal = {IEEE Computer Graphics and Applications},
  year    = {2001},
}

@ARTICLE{cruzneira:92,
  author = {{Cruz-Neira,~C.} and {Sandin,~D.~J.} and {DeFanti,~T.~A.} and {Kenyon,~R.~V.}
	and {Hart,~J.~C.}},
  title = {The {CAVE}: audio visual experience automatic virtual environment},
  journal = cacm,
  year = {1992},
  volume = {35},
  pages = {64--72},
  number = {6}
}

@INPROCEEDINGS{bierbaum:98,
  author = {{Bierbaum,~A.} and {Cruz-Neira,~C.} and {Just,~C.} and {Hartling,~P.}
	and {Meiner,~K.} and {Baker,~A.}},
  title = {{VR} {Juggler}: A Virtual Platform for Virtual Reality Application
	Development},
  booktitle = {IEEE Proceedings of Virtual Reality},
  year = {1998},
  pages = {89--96}
}

@Article{brooks:99,
  author    = {{Brooks, Frederick}},
  title     = {What's Real About Virtual Reality?},
  number    = {6},
  pages     = {16--27},
  volume    = {19},
  journal   = {IEEE Comput. Graph. Appl.},
  publisher = {IEEE Computer Society Press},
  year      = {1999},
}

@MANUAL{lipton:97,
  title = {The StereoGraphics Developer's Handbook},
  author = {Lipton, L.},
  organization = {StereoGraphics Corporation},
  year = {1997}
}

@MANUAL{heilig:62,
  title = {Sensorama Simulator, U.S. Patent $3\:050\:870$},
  author = {Heilig, Morton},
  organization = {United States Patent and Trademark Office},
  year = {1962}
}

@MANUAL{glitz:94,
  title = {Virtuelle Realität - Arbeitsbericht zur Technikfolgenabschätzung},
  author = {Glitz, Raimund},
  organization = {VDI Technologiezentrum Physikalische Technologien},
  year = {1994}
}

@MANUAL{massie:94,
  title = {The phantom haptic interface: A device for probing virtual objects},
  author = {T. H. Massie and J. K. Salisbury},
  year = {1994},
  pages = {295--302}
}

@InProceedings{brooks:71,
  author    = {{Batter,~J.~J.} and {Brooks,~Frederick}},
  booktitle = {Proc. IFIP Congress},
  title     = {{GROPE-I}: A computer display to the sense of feel},
  pages     = {759--763},
  year      = {1971},
}

@INPROCEEDINGS{thalmann:97,
  author = {{Magnenat-Thalmann,~N.} and {Pandzic,~I.} and {Joussaly,~J.-C.}},
  title = {The Making of the {Terra-Cotta} {Xian} Soldiers},
  booktitle = {Digitalized 97: Proceedings in Digital Creativity},
  year = {1997},
  pages = {66-73}
}

@ARTICLE{lepetit:05,
  author = {{Lepetit,~V.} and {Fua,~P.}},
  title = {Monocular Model-Based {3D} Tracking of Rigid Objects: A Survey},
  journal = {Foundations and Trends in Computer Graphics and Vision},
  year = {2005},
  volume = {1},
  pages = {1-89},
  number = {1}
}

@InProceedings{steinicke:05,
  author    = {{Steinicke,~Frank.} and {Ropinski,~T.} and {Hinrichs,~Klaus }},
  title     = {A Generic Virtual Reality Software System's Architecture and Application},
  booktitle = {Proceedings of the 10th International Conference on Human-Computer Interaction (INTERACT05)},
  year      = {2005},
  pages     = {1018-1021},
}

@INPROCEEDINGS{anthes:04,
  author = {{Anthes,~C.} and {Heinzlreiter,~P.} and {Kurka,~G.} and {Volkert,~J.}},
  title = {Navigation models for a flexible, multi-mode {VR} navigation framework},
  booktitle = {VRCAI '04: Proceedings of the 2004 ACM SIGGRAPH international conference
	on Virtual Reality continuum and its applications in industry},
  year = {2004},
  pages = {476--479},
  publisher = {ACM}
}

@InProceedings{bowman:99,
  author    = {{Bowman, Doug} and {Johnson, Donald} and {Hodges, Larry}},
  booktitle = {Proceedings of the ACM symposium on Virtual reality software and technology (VRST)},
  title     = {Testbed evaluation of virtual environment interaction techniques},
  pages     = {26--33},
  publisher = {ACM},
  year      = {1999},
}

@InProceedings{bowman_07,
  author    = {{Ray,~Andrew} and {Bowman,~Doug}},
  title     = {Towards a System for Reusable {3D} Interaction Techniques},
  booktitle = {Proceedings of the ACM symposium on Virtual reality software and technology (VRST)},
  year      = {2007},
  publisher = {ACM},
  pages     = {187--190},
}

@INPROCEEDINGS{robinett:92,
  author = {{Robinett,~W.} and {Holloway,~R.}},
  title = {Implementation of flying, scaling and grabbing in virtual worlds},
  booktitle = {SI3D '92: Proceedings of the 1992 symposium on Interactive 3D graphics},
  year = {1992},
  pages = {189--192},
  publisher = {ACM}
}

@MANUAL{mine:95,
  title = {Virtual Environment Interaction Techniques},
  author = {Mark R. Mine},
  organization = {University of North Carolina at Chapel Hill},
  year = {1995}
}

@MANUAL{meinert:02,
  title = {Travel systems for virtual environments},
  author = {Kevin Meinert},
  organization = {Course Notes for Open Source Virtual Reality, IEEE VR 2002},
  year = {2002}
}

@InProceedings{bowman:97,
  author       = {{Bowman, Doug} and {Koller, David} and {Hodges, Larry }},
  title        = {Travel In Immersive Virtual Environments: An Evaluation of Viewpoint Motion Control Techniques},
  booktitle    = {Proceedings of VRAIS'97},
  year         = {1997},
  organization = {IEEE Computer Society},
  pages        = {45--52},
  abstract     = {We present a categorization of techniques for firstperson motion control,
	or travel, through immersive virtual environments, as well as a framework
	for evaluating the quality of different techniques for specific virtual
	environment tasks. We conduct three quantitative experiments within
	this framework: a comparison of different techniques for moving directly
	to a target object varying in size and distance, a comparison of
	different techniques for moving relative to a reference object, and
	a comparison of different motion techniques and their resulting sense
	of “disorientation” in the user. Results indicate that “pointing”
	techniques are advantageous relative to “gaze-directed” steering
	techniques for a relative motion task, and that motion techniques
	which instantly teleport users to new locations are correlated with
	increased user disorientation.},
  keywords     = {locomotion},
}

@InProceedings{brooks:99a,
  author    = {{Usoh,~Martin} and {Arthur,~K.} and {Whitton,~M.} and {Bastos,~R.} and {Steed,~Anthony} and {Slater,~M.} and {Brooks,~Frederick}},
  booktitle = {Proceedings of SIGGRAPH 1999},
  title     = {Walking $>$ Walking-in-Place $>$ Flying in Virtual Environments},
  pages     = {359--364},
  publisher = {ACM},
  year      = {1999},
}

@INPROCEEDINGS{kelso:02,
  author = {{Kelso,~J.} and {Arsenault,~L.} and {Satterfield,~S.} and {Kriz,~R.}},
  title = {{DIVERSE}: A framework for building extensible and reconfigurable
	device independent virtual environments},
  booktitle = {Proceedings of IEEE Virtual Reality 2002 Conference},
  year = {2002},
  pages = {183--190},
  publisher = {IEEE}
}

@InProceedings{steinicke:09,
  author    = {{Steinicke, Frank} and {Bruder, Gerd} and {Hinrichs, Klaus} and {Steed, Anthony}},
  booktitle = {Proceedings of the 2009 ACM SIGGRAPH Symposium on Video Games},
  title     = {Presence-enhancing real walking user interface for first-person video games},
  doi       = {http://doi.acm.org/10.1145/1581073.1581091},
  location  = {New Orleans, Louisiana},
  pages     = {111--118},
  publisher = {ACM},
  series    = {Sandbox '09},
  abstract  = {For most first-person video games it is important that players have
	a high level of feeling presence in the displayed game environment.
	Virtual reality (VR) technologies have enormous potential to enhance
	gameplay since players can experience the game immersively from the
	perspective of the player's virtual character. However, the VR technology
	itself, such as tracking devices and cabling, has until recently
	restricted the ability of users to really walk over long distances.
	
	 In this paper we introduce a VR-based user interface for presence-enhancing
	gameplay with which players can explore the game environment in the
	most natural way, i. e., by real walking. While the player walks
	through the virtual game environment, we guide him/her on a physical
	path which is different from the virtual path and fits into the VR
	laboratory space. In order to further increase the VR experience,
	we introduce the concept of transitional environments. Such a transitional
	environment is a virtual replica of the laboratory environment, where
	the VR experience starts and which enables a gradual transition to
	the game environment. We have quantified how much humans can unknowingly
	be redirected and whether or not a gradual transition to a first-person
	game via a transitional environment increases the user's sense of
	presence.},
  keywords  = {virtual reality, walking interface},
  year      = {2009},
}

@INPROCEEDINGS{terziman:10,
  author = {Terziman, L\'{e}o and Marchal, Maud and Emily, Mathieu and Multon,
	Franck and Arnaldi, Bruno and L\'{e}cuyer, Anatole},
  title = {Shake-your-head: revisiting walking-in-place for desktop virtual
	reality},
  booktitle = {Proceedings of the 17th ACM Symposium on Virtual Reality Software
	and Technology},
  year = {2010},
  series = {Proceedings of the ACM symposium on Virtual reality software and
	technology (VRST)},
  pages = {27--34},
  publisher = {ACM},
  abstract = {The Walking-In-Place interaction technique was introduced to navigate
	infinitely in 3D virtual worlds by walking in place in the real world.
	The technique has been initially developed for users standing in
	immersive setups and was built upon sophisticated visual displays
	and tracking equipments.
	
	
	 In this paper, we propose to revisit the whole pipeline of the Walking-In-Place
	technique to match a larger set of configurations and apply it notably
	to the context of desktop Virtual Reality. With our novel "Shake-Your-Head"
	technique, the user is left with the possibility to sit down, and
	to use small screens and standard input devices such as a basic webcam
	for tracking. The locomotion simulation can compute various motions
	such as turning, jumping and crawling, using as sole input the head
	movements of the user. We also introduce the use of additional visual
	feedback based on camera motions to enhance the walking sensations.
	
	
	 An experiment was conducted to compare our technique with classical
	input devices used for navigating in desktop VR. Interestingly, the
	results showed that our technique could even allow faster navigations
	when sitting, after a short learning. Our technique was also perceived
	as more fun and increasing presence, and was generally more appreciated
	for VR navigation.},
  doi = {http://doi.acm.org/10.1145/1889863.1889867},
  keywords = {desktop virtual reality, first-person-navigation, walking},
  location = {Hong Kong}
}

@INPROCEEDINGS{darken:97,
  author = {Rudolph P. Darken and William R. Cockayne and David Carmein},
  title = {The Omni-Directional Treadmill: A Locomotion Device for Virtual Worlds},
  booktitle = {UIST '97: Proceedings of the 10th annual ACM symposium on User interface
	software and technology},
  year = {1997},
  pages = {213--221},
  abstract = {The Omni-Directional Treadmill (ODT) is a revolutionary device for
	locomotion in large-scale virtual environments. The device allows
	its user to walk or jog in any direction of travel. It is the third
	generation in a series of devices built for this purpose for the
	U.S. Army's Dismounted Infantry Training Program. We first describe
	the device in terms of its construction and operating characteristics.
	We then report on an analysis consisting of a series of locomotion
	and maneuvering tasks on the ODT. We observed user motions and system
	responses to those motions from the perspective of the user. Each
	task is described in terms of what causes certain motions to trigger
	unpredictable responses causing loss of balance or at least causing
	the user to become consciously aware of their movements. We conclude
	that the two primary shortcomings in the ODT are its tracking system
	and machine control mechanism for centering the user on the treads.}
}

@INPROCEEDINGS{interrante:07,
  author = {Victoria Interrante and Brian Ries and Lee Anderson},
  title = {Seven league boots: An new metaphor for augmented locomotion through
	large scale immersive virtual environments},
  booktitle = {In Proceedings of IEEE Symposium on 3D User Interfaces (3DUI},
  year = {2007},
  publisher = {IEEE Computer Society},
  abstract = {When an immersive virtual environment represents a space that is larger
	than the available space within which a user can travel by directly
	walking, it becomes necessary to consider alternative methods for
	traveling through that space. The traditional solution is to require
	the user to travel ‘indirectly’, using a device that changes his
	viewpoint in the environment without actually requiring him to move
	– for example, a joystick. However, other solutions involving variations
	on direct walking are also possible.
	
	 In this paper, we present a new metaphor for natural, augmented direct
	locomotion through moderately large-scale immersive virtual environments
	(IVEs) presented via head mounted display systems, which we call
	seven league boots. The key characteristic of this method is that
	it involves determining a user’s intended direction of travel and
	then augmenting only the component of his or her motion that is aligned
	with that direction.
	
	 After reviewing previously proposed methods for enabling intuitive
	locomotion through large IVEs, we begin by describing the technical
	implementation details of our novel method, discussing the various
	alternative options that we explored and parameters that we varied
	in an attempt to attain optimal performance. We then present the
	results of a pilot observer experiment that we conducted in an attempt
	to obtain objective, qualitative insight into the relative strengths
	and weaknesses of our new method, in comparison to the three most
	commonly used alternative locomotion methods: flying, via use of
	a wand; normal walking, with a uniform gain applied to the output
	of the tracker; and normal walking without gain, but with the location
	and orientation of the larger virtual environment periodically adjusted
	relative to position of the participant in the real environment.
	In this study we found, among other things, that for travel down
	a long, straight virtual hallway, participants overwhelmingly preferred
	the seven league boots method to the other methods, overall.}
}

@INPROCEEDINGS{iwata_06,
  author = {Iwata, Hiroo and Yano, Hiroaki and Tomioka, Hiroshi},
  title = {Powered shoes},
  booktitle = {ACM SIGGRAPH 2006 Emerging technologies},
  year = {2006},
  series = {SIGGRAPH '06},
  publisher = {ACM},
  abstract = {Powered Shoes is a locomotion interface using roller skates actuated
	by two motors with flexible shafts. The device is light-weighted
	and wearable. It enables the user to walk in virtual environment
	while his/her position is maintained. The user can walk in arbitrary
	direction in virtual environment.},
  doi = {http://doi.acm.org/10.1145/1179133.1179162},
  keywords = {Locomotion, Walking}
}

@InProceedings{steinicke:09a,
  author    = {{Steinicke, Frank} and {Bruder, Gerd} and {Hinrichs, Klaus} and {Lappe, Markus} and {Ries, Brian} and {Interrante, Victoria}},
  title     = {Transitional environments enhance distance perception in immersive virtual reality systems},
  booktitle = {Proceedings of the 6th Symposium on Applied Perception in Graphics and Visualization},
  year      = {2009},
  series    = {APGV '09},
  pages     = {19--26},
  doi       = {http://doi.acm.org/10.1145/1620993.1620998},
  abstract  = {Several experiments have provided evidence that ego-centric distances
	are perceived as compressed in immersive virtual environments relative
	to the real world. The principal factors responsible for this phenomenon
	have remained largely unknown. However, recent experiments suggest
	that when the virtual environment (VE) is an exact replica of a user's
	real physical surroundings, the person's distance perception improves.
	Furthermore, it has been shown that when users start their virtual
	reality (VR) experience in such a virtual replica and then gradually
	transition to a different VE, their sense of presence in the actual
	virtual world increases significantly. In this case the virtual replica
	serves as a transitional environment between the real and virtual
	world.
	
	 In this paper we examine whether a person's distance estimation skills
	can be transferred from a transitional environment to a different
	VE. We have conducted blind walking experiments to analyze if starting
	the VR experience in a transitional environment can improve a person's
	ability to estimate distances in an immersive VR system. We found
	that users significantly improve their distance estimation skills
	when they enter the virtual world via a transitional environment.},
  keywords  = {distance estimation, transitional environment, virtual reality},
}

@InProceedings{steinicke:09b,
  author    = {{Steinicke, Frank} and {Bruder, Gerd} and {Hinrichs, Klaus} and {Steed, Anthony} and {Gerlach, Alexander}},
  title     = {Does a Gradual Transition to the Virtual World increase Presence?},
  booktitle = {Proceedings of the 2009 IEEE Virtual Reality Conference},
  year      = {2009},
  publisher = {IEEE Computer Society},
  pages     = {203--210},
  doi       = {10.1109/VR.2009.4811024},
  abstract  = {In order to increase a user's sense of presence in an artificial environment
	some researchers propose a gradual transition from reality to the
	virtual world instead of immersing users into the virtual world directly.
	One approach is to start the VR experience in a virtual replica of
	the physical space to accustom users to the characteristics of VR,
	e.g., latency, reduced field of view or tracking errors, in a known
	environment. Although this procedure is already applied in VR demonstrations,
	until now it has not been verified whether the usage of such a transitional
	environment - as transition between real and virtual environment
	- increases someone's sense of presence. We have observed subjective,
	physiological and behavioral reactions of subjects during a fully-immersive
	flight phobia experiment under two different conditions: the virtual
	flight environment was displayed immediately, or subjects visited
	a transitional environment before entering the virtual flight environment.
	We have quantified to what extent a gradual transition to the VE
	via a transitional environment increases the level of presence. We
	have found that subjective responses show significantly higher scores
	for the user's sense of presence, and that subjects' behavioral reactions
	change when a transitional environment is shown first. Considering
	physiological reactions, no significant difference could be found.},
  address   = {Washington, DC, USA},
}

@INPROCEEDINGS{razzaque:01,
  author = {Sharif Razzaque and Zachariah Kohn and Mary C. Whitton},
  title = {Redirected Walking},
  booktitle = {Proceedings of Eurographics},
  year = {2001},
  pages = {289--294},
  month = {September},
  publisher = {Eurographics Association},
  abstract = {Redirected Walking, a new interactive locomotion technique for virtual
	environments (VEs), captures the benefits of real walking while extending
	the possible size of the VE. Real walking, although natural and producing
	a high subjective sense of presence, limits virtual environments
	to the size of the tracked space.
	
	 Redirected Walking addresses this limitation by interactively and
	imperceptibly rotating the virtual scene about the user. The rotation
	causes the user to walk continually toward the furthest wall of the
	lab without noticing the rotation. We implemented the technique using
	stereo graphics and 3D spatialized audio. Observations during a pilot
	study suggest that the technique works: Redirected Walking causes
	people to change their real walking direction without noticing it,
	allows for larger VEs, and does not induce appreciable simulator
	sickness.}
}

@InProceedings{steed_02,
  author    = {{Razzaque, Sharif} and {Swapp, David} and {Slater, Mel} and {Whitton, Mary} and {Steed, Anthony}},
  booktitle = {Proceedings of the Workshop on Virtual environments 2002},
  title     = {Redirected walking in place},
  location  = {Barcelona, Spain},
  pages     = {123--130},
  publisher = {Eurographics Association},
  series    = {EGVE '02},
  url       = {http://portal.acm.org/citation.cfm?id=509709.509729},
  abstract  = {This paper describes a method for allowing people to virtually move
	around a CAVE™ without ever having to turn to face the missing back
	wall. We describe the method, and report a pilot study of 28 participants,
	half of whom moved through the virtual world using a hand-held controller,
	and the other half used the new technique called ‘Redirected Walking
	in Place’ (RWP). The results show that the current instantiation
	of the RWP technique does not result in a lower frequency of looking
	towards the missing wall. However, the results also show that the
	sense of presence in the virtual environment is significantly and
	negatively correlated with the amount that the back wall is seen.
	There is evidence that RWP does reduce the chance of seeing the blank
	wall for some participants. The increased sense of presence through
	never having to face the blank wall, and the results of this pilot
	study show the RWP has promise and merits further development.},
  year      = {2002},
}

@INPROCEEDINGS{xie:10,
  author = {Xie, Xianshi and Lin, Qiufeng and Wu, Haojie and Narasimham, Gayathri
	and McNamara, Timothy P. and Rieser, John and Bodenheimer, Bobby},
  title = {A system for exploring large virtual environments that combines scaled
	translational gain and interventions},
  booktitle = {Proceedings of the 7th Symposium on Applied Perception in Graphics
	and Visualization},
  year = {2010},
  series = {APGV '10},
  pages = {65--72},
  publisher = {ACM},
  abstract = {This paper evaluates the combination of two methods for adapting bipedal
	locomotion to explore virtual environments displayed on head-mounted
	displays (HMDs) within the confines of limited tracking spaces. We
	combine a method of changing the optic flow of locomotion, effectively
	scaling the translational gain, with a method of intervening and
	manipulating a user's locations in physical space while preserving
	their spatial awareness of the virtual space. This latter technique
	is called resetting. In two experiments, we evaluate both scaling
	the translational gain and resetting while a subject locomotes along
	a path and then turns to face a remembered object. We find that the
	two techniques can be effectively combined, although there is a cognitive
	cost to resetting.},
  doi = {http://doi.acm.org/10.1145/1836248.1836260},
  keywords = {space perception, virtual reality},
  location = {Los Angeles, California}
}

@InProceedings{brooks_05,
  author    = {{Cohn, Joseph} and {Feasel, Jeff} and {Poulton, Sarah} and {McLeod, Brandi} and {Brooks., Frederick}},
  booktitle = {Proceedings of the 2005 IEEE Conference 2005 on Virtual Reality},
  title     = {Comparing VE Locomotion Interfaces},
  pages     = {123--130},
  publisher = {IEEE Computer Society},
  series    = {VR '05},
  abstract  = {To compare and evaluate locomotion interfaces for users who are (virtually)
	moving on foot in VEs, we performed a study to characterize task
	behavior and task performance with different visual and locomotion
	interfaces. In both a computer-generated environment and a corresponding
	real environment, study participants walked to targets on walls and
	stopped as close to them as they could without making contact.
	
	 In each of five experimental conditions participants used a combination
	of one of three locomotion interfaces (really walking, walking-in-place,
	and joystick flying), and one of three visual conditions (head-mounted
	display, unrestricted natural vision, or field-of-view-restricted
	natural vision). We identified metrics and collected data that captured
	task performance and the underlying kinematics of the task.
	
	 Our results show: 1) Over 95% of the variance in simple motion paths
	is captured in three critical values: peak velocity; when, in the
	course of a motion, the peak velocity occurs; and peak deceleration.
	2) Correlations of those critical value data for the conditions taken
	pairwise suggest a coarse ordering of locomotion interfaces by “naturalness.”
	3) Task performance varies with interface condition, but correlations
	of that value for conditions taken pairwise do not cluster by naturalness.
	4) The perceptual variable, τ (also known as the time-to-contact)
	calculated at the point of peak deceleration has higher correlation
	with task performance than τ calculated at peak velocity.},
  keywords  = {Locomotion, perception-action},
  year      = {2005},
}

@Article{steed_95,
  author   = {{Slater, Mel} and {Usoh, Martin} and {Steed, Anthony}},
  title    = {Taking steps: the influence of a walking technique on presence in virtual reality},
  doi      = {http://doi.acm.org/10.1145/210079.210084},
  issue    = {3},
  pages    = {201--219},
  volume   = {2},
  abstract = {This article presents an interactive technique for moving through
	an immersive virtual environment (or “virtual reality”). The technique
	is suitable for applications where locomotion is restricted to ground
	level. The technique is derived from the idea that presence in virtual
	environments may be enhanced the stronger the match between proprioceptive
	information from human body movements and sensory feedback from the
	computer-generated displays. The technique is an attempt to simulate
	body movements associated with walking. The participant “walks in
	place” to move through the virtual environment across distances greater
	than the physical limitations imposed by the electromagnetic tracking
	devices. A neural network is used to analyze the stream of coordinates
	from the head-mounted display, to determine whether or not the participant
	is walking on the spot. Whenever it determines the walking behavior,
	the participant is moved through virtual space in the direction of
	his or her gaze. We discuss two experimental studies to assess the
	impact on presence of this method in comparison to the usual hand-pointing
	method of navigation in virtual reality. The studies suggest that
	subjective rating of presence is enhanced by the walking method provided
	that participants associate subjectively with the virtual body provided
	in the environment. An application of the technique to climbing steps
	and ladders is also presented.},
  journal  = {ACM Trans. Comput.-Hum. Interact.},
  keywords = {locomotion, presence, virtual reality},
  year     = {1995},
}

@InProceedings{feasel_08,
  author    = {Feasel, J. and Whitton, M. C. and Wendt, J. D.},
  booktitle = {Proceedings of the 2008 IEEE Symposium on 3D User Interfaces},
  title     = {LLCM-WIP: Low-Latency, Continuous-Motion Walking-in-Place},
  doi       = {http://dx.doi.org/10.1109/3DUI.2008.4476598},
  pages     = {97--104},
  publisher = {IEEE Computer Society},
  series    = {3DUI '08},
  abstract  = {Walking-in-place techniques for locomotion in virtual environments
	typically have two problems that impact their usability: system latency
	(particularly troublesome when starting and stopping locomotion),
	and the fact that the change in the user's viewpoint may not be smooth
	and continuous. This paper describes a new WIP interface that improves
	both latency and the continuity of synthesized locomotion in the
	virtual environment. By basing the virtual avatar motion on the speed
	of the user's heel motion while walking in place, we create a direct
	mapping from foot-motion to locomotion that is responsive, intuitive,
	and easy to implement. In this paper, we describe the technique,
	analyze its starting and stopping latency, and provide experimental
	results on the suppression of false steps and general usability of
	the system.},
  keywords  = {locomotion},
  year      = {2008},
}

@InProceedings{brooks:10,
  author       = {{Wendt, Jeremy} and {Whitton, Mary} and {Brooks, Frederick}},
  booktitle    = {Proceedings of IEEE Virtual Reality},
  title        = {Gud wip: Gait-understanding-driven walking-in-place},
  organization = {IEEE Computer Society},
  pages        = {51--58},
  abstract     = {Many Virtual Environments require walking interfaces to explore virtual
	worlds much larger than available real-world tracked space. We present
	a model for generating virtual locomotion speeds from Walking-In-Place
	(WIP) inputs based on walking biomechanics. By employing gait principles,
	our model – called Gait- Understanding-DrivenWalking-In-Place (GUD
	WIP) – creates output speeds which better match those evident in
	Real Walking, and which better respond to variations in step frequency,
	including realistic starting and stopping. The speeds output by our
	implementation demonstrate considerably less within-step fluctuation
	than a good current WIP system – Low-Latency, Continuous-Motion (LLCM)
	WIP – while still remaining responsive to changes in user input.
	
	 We compared resulting speeds from Real Walking, GUD WIP, and LLCM-WIP
	via user study: The average output speeds for Real Walking and GUD
	WIP respond consistently with changing step frequency – LLCM-WIP
	is far less consistent. GUD WIP produces output speeds that are more
	locally consistent (smooth)},
  keywords     = {locomotion, virtual reality},
  year         = {2010},
}

@INPROCEEDINGS{domik_05,
  author = {{Redmer, Benedikt} and {Goetz, Frank} and {Domik, Gitta}},
  title = {Eine {A}bstraktion von {E}ingabeger"aten zur {V}erwendung in {A}ugmented
	{R}eality {A}nwendungen},
  booktitle = {Workshop Virtuelle und Erweiterte Realit"at der GI-Fachgruppe VR/AR},
  year = {2005},
  organization = {GI},
  abstract = {Einhergehend mit der Entwicklung der Virtual Reality (VR) und Augmented
	Reality (AR) Technologie, wobei die letztere die optische Wahrnehmung
	der Umgebung des Menschen durch virtuelle Objekte erweitert, werden
	immer wieder neue und sehr spezielle Ein- und Ausgabegeräte entwickelt.
	Dadurch wird es immer aufwendiger sämtliche verfügbare Hardware in
	zukünftige Anwendungen zu integrieren. Aufbauend auf dem Konzept
	der virtuellen Eingabegeräte wurde die Augmented Reality Input Device
	Abstraction (ARIDA) Programmierschnittstelle (API) in C++ entworfen,
	die es Softwareentwicklern ermöglicht verschiedenste Eingabegeräte
	über eine einheitliche Schnittstelle anzusprechen.
	
	 Der modulare Aufbau von ARIDA erlaubt es, neue Gerätetypen mit ihren
	eigenen, neuen Eigenschaften, aus der Kombination unterschiedlicher
	realer Hardware zusammenzusetzen.},
  keywords = {VR, Eingabe}
}

@InProceedings{taylor_01,
  author       = {{Taylor, Russell} and {Hudson, Thomas} and {Seeger, Adam} and {Weber, Hans} and {Juliano, Jeffrey} and {Helser, Aron}},
  booktitle    = {Proceedings of the ACM symposium on Virtual reality software and technology (VRST)},
  title        = {{V}{R}{P}{N}: a device-independent, network-transparent VR peripheral system},
  organization = {ACM},
  pages        = {55--61},
  url          = {\url{http://doi.acm.org/10.1145/505008.505019}},
  keywords     = {input devices, interactive graphics, library, peripherals, virtual environments, virtual worlds},
  year         = {2001},
}

@INPROCEEDINGS{kontkanen_02,
  author = {Tommi Ilmonen and Janne Kontkanen},
  title = {Software Architecture for Multimodal User Input - FLUID},
  booktitle = {In The Proceedings of the 7th ERCIM Workshop},
  year = {2002},
  pages = {223--242},
  organization = {ERCIM}
}

@INPROCEEDINGS{schmalstieg_01,
  author = {Gerhard Reitmayr and Dieter Schmalstieg},
  title = {An Open Software Architecture for Virtual Reality Interaction},
  booktitle = {Proceedings of the ACM symposium on Virtual reality software and
	technology (VRST)},
  year = {2001},
  pages = {47--54},
  publisher = {ACM Press}
}

@INPROCEEDINGS{dragicevic_04,
  author = {Dragicevic, Pierre and Fekete, Jean-Daniel},
  title = {Support for input adaptability in the {I}{C}{O}{N} toolkit},
  booktitle = {Proceedings of the 6th international conference on Multimodal interfaces},
  year = {2004},
  series = {ICMI '04},
  pages = {212--219},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1027933.1027969},
  keywords = {adaptability, input devices, interaction techniques, toolkits, visual
	programming},
  url = {http://doi.acm.org/10.1145/1027933.1027969}
}

@INPROCEEDINGS{pietriga_11,
  author = {Pietriga, Emmanuel and Huot, Stephane and Nancel, Mathieu and Primet,
	Romain},
  title = {Rapid Development of User Interfaces on Cluster-Driven Wall Displays
	with jBricks},
  booktitle = {Symposium on Engineering Interactive Computing Systems},
  year = {2011},
  organization = {SIGCHI},
  publisher = {ACM},
  keywords = {Interfaces, peripherals}
}

@InProceedings{rizzo_11,
  author    = {{Suma, Evan} and {Lange, Belinda} and {Rizzo, Skip} and {Krum, David} and {Bolas, Mark}},
  title     = {FAAST: The Flexible Action and Articulated Skeleton Toolkit},
  booktitle = {Proceedings of IEEE Virtual Reality},
  year      = {2011},
  pages     = {212--248},
}

@BOOK{stary_94,
  title = {Interaktive Systeme -- Software-Entwicklung und Software-Ergonomie},
  publisher = {Vieweg},
  year = {1994},
  author = {Stary, Christian},
  note = {I945/2}
}

@Book{raskin_00,
  author    = {Raskin, Jef},
  title     = {The Humane Interface -- New Directions for Designing Interactive Systems},
  year      = {2000},
  publisher = {Addison-Wesley},
}

@BOOK{norman_02,
  title = {The Design of Everyday Things},
  publisher = {Perseus Books},
  year = {2002},
  author = {Norman, Donald}
}

@BOOK{johnson_00,
  title = {GUI Bloopers: Don'ts and Do's for Software Developers and Web Designers},
  publisher = {Morgan Kaufmann},
  year = {2000},
  author = {Johnson, Jeff}
}

@BOOK{johnson_07,
  title = {GUI Bloopers 2.0: Commom User Interface Design Don'ts and Do's},
  publisher = {Morgan Kaufmann},
  year = {2007},
  author = {Johnson, Jeff}
}

@BOOK{preece_94,
  title = {Human-Computer Interaction},
  publisher = {Addison-Wesley},
  year = {1994},
  author = {Preece, Jenny}
}

@BOOK{tidwell_11,
  title = {Design Interfaces},
  publisher = {OReilly},
  year = {2011},
  author = {Tidwell, Jenifer}
}

@BOOK{cooper_07,
  title = {About Face 3: The Essentials of Interaction Design},
  publisher = {Wiley},
  year = {2007},
  author = {{Cooper, Alan} and {Reimann, Robert} and {Cronin, David}}
}

@BOOK{summerfield_08,
  title = {C++ GUI Programming with Qt4},
  publisher = {Prentice Hall},
  year = {2008},
  author = {{Blanchette, Jasmin} and {Summerfield, Marc}}
}

@BOOK{summerfield_10,
  title = {Advanced Qt Programming -- Creating Great Software with C++ and Qt4},
  publisher = {Prentice Hall},
  year = {2010},
  author = {Summerfield, Marc}
}

@BOOK{wolf_07,
  title = {Qt4 -- GUI-Entwicklung mit C++: Das umfassende Handbuch},
  publisher = {Galileo Computing},
  year = {2007},
  author = {Wolf, J\"urgen}
}

@BOOK{widjaja_08,
  title = {Rich Internet Applications mit Adobe Flex 3},
  publisher = {Hanser},
  year = {2008},
  author = {Simon Widjaja}
}

@BOOK{kipper_13,
  title = {Augmented Reality -- An Emerging Technologies Guide to AR},
  publisher = {Elsevier},
  year = {2013},
  author = {{Kipper, Gregory} and {Rampolla, Joseph}},
  edition = {1.}
}

@Electronic{middlevr,
  author       = {MiddleVR},
  title        = {Virtual Reality for Professionals},
  url          = {\url{http://www.middlevr.com/home/}},
  note         = {Zuletzt gesehen: 03. Juli 2022},
  howpublished = {\url{http://www.middlevr.com/home/}},
}

@ARTICLE{milgram_94,
  author = {{Milgram, Paul} and {Kishino, Furnio}},
  title = {A Taxonomy of Mixed Reality Visual Displays},
  journal = {IEICE Transactions on Information and Systems},
  year = {1994},
  volume = {E77-D},
  pages = {1321-1329},
  number = {12},
  booktitle = {IEICE Trans. Info}
}

@BOOK{toennis_10,
  title = {Augmented Reality -- Einblicke in die erweiterte Realität},
  publisher = {Springer},
  year = {2010},
  author = {Tönnis, Marcus},
  edition = {Informatik im Fokus},
  comment = {I800/192},
  doi = {http://dx.doi.org/10.1007/978-3-642-14179-9},
  url = {https://link.springer.com/book/10.1007%2F978-3-642-14179-9}
}

@ELECTRONIC{middlevruser,
  author = {MiddleVR},
  title = {MiddleVR User Guide},
  howpublished = {\url{https://www.middlevr.com/doc/current/}},
  note = {Zuletzt gesehen: 06. M"arz 2019},
  url = {https://www.middlevr.com/doc/current/}
}

@ELECTRONIC{iatksite,
  author = {Cordeil, Maxime},
  title = {Immersive Analytics Toolkit},
  howpublished = {\url{https://github.com/MaximeCordeil/IATK}},
  url = {\url{https://github.com/MaximeCordeil/IATK}}
}

@Electronic{vrtksite,
  author       = {VRTK},
  title        = {Virtual Reality Toolkit - A productive VR Toolkit for rapidly building VR solutions in Unity3D},
  url          = {\url{https://vrtoolkit.readme.io/}},
  note         = {Zuletzt gesehen: 25. Oktober 2018},
  howpublished = {\url{https://vrtoolkit.readme.io/}},
}

@ELECTRONIC{dxrsite,
  author = {Sicat, Ronell},
  howpublished = {\url{https://sites.google.com/view/dxr-vis/home}},
  note = {Zuletzt gesehen 30. Oktober 2018},
  url = {\url{https://sites.google.com/view/dxr-vis/home}}
}

@INPROCEEDINGS{ronell_18,
  author = {{Ronell, Sicat} and {Choi, JunYoung} and {Cordeil, Maxime} and {Jeong,
	Won-Ki} and {Bach, Benjamin} and {Pfister, Hanspeter}},
  title = {DXR: A Toolkit for Building Immersive Data Visualizations},
  booktitle = {Information Visualization},
  year = {2018}
}

@BOOK{bormann:04,
  title = {Virtuelle Realit\"at - Genese und Evaluation},
  publisher = {Addison-Wesley},
  year = {1994},
  author = {Bormann, Sven}
}

@BOOK{jerald:15,
  title = {The VR Book: Human-Centered Design for Virtual Reality},
  publisher = {Morgan and Claypool Publischers},
  year = {2015},
  author = {{Jerald, Jason}}
}

@BOOK{linowes:15,
  title = {Unity Virtual Reality Business - Explore the world of virtual reality
	by building immersive and fun VR projects using Unity3D},
  publisher = {Packt Publishing},
  year = {2015},
  author = {{Linowes, Jonathan}}
}

@BOOK{linowes:17,
  title = {Augmented Reality for Developers: Build practical augmented reality
	applications with Unity, ARCore, ARKit, and Vuforia},
  publisher = {Packt Publishing},
  year = {2017},
  author = {{Linowes, Jonathan}}
}

@BOOK{murray:17,
  title = {Building Virtual Reality with Unity and Steam VR},
  publisher = {Routledge},
  year = {2017},
  author = {Murray, Jeff}
}

@BOOK{korgel:17,
  title = {Virtual Reality-Spiele entwickeln mit Unity: Grundlagen, Beispielprojekte,
	Tipps und Tricks},
  publisher = {Hanser},
  year = {2017},
  author = {Korgel, Daniel}
}

@Book{schmalstieg_16,
  author    = {{Schmalstieg, Dieter} and {Hollerer, Tobias}},
  title     = {Augmented Reality: Principles and Practice},
  publisher = {Addison-Wesley},
  year      = {2016},
}

@BOOK{parisi:15,
  title = {Learning Virtual Reality},
  publisher = {OReilly},
  year = {2015},
  author = {Parisi, Tony}
}

@BOOK{doerner:13,
  title = {Virtual und Augmented Reality (AR/VR)},
  publisher = {Springer Vieweg},
  year = {2013},
  author = {{D"orner, Ralf} and {Broll, Wolfgang} and {Grimm, Paul} and {Jung,
	Bernhard}}
}

@BOOK{sherman:19,
  title = {Understanding Virtual Reality - Interface, Application, and Design},
  publisher = MK,
  year = {2019},
  author = {{Shermann, William R.} and {Craig, Alan B.}},
  edition = {2.}
}

@BOOK{galouye:64,
  title = {Simulacron-3},
  publisher = {Bantam Books},
  year = {1964},
  author = {Galouye, Daniel}
}

@InProceedings{zayer_18,
  author    = {{Zayer, Majed Al} and {MacNeilage, Paul} and {Folmer, Eelke}},
  booktitle = {Trans. on Visualization and Computer Graphics},
  date      = {2018},
  title     = {Virtual Locomotion: a Survey},
  year      = {2018},
}

@INPROCEEDINGS{lindeman_16,
  author = {{Yan, Zhixin} and {Lindeman, Robert} and {Dey, Arindam}},
  title = {Let Your Fingers do the Walking: A Unified Approach for Efficient
	Short-, Medium-, and Long-Distance Travel in VR},
  booktitle = {IEEE Symposium on 3D User Interfaces},
  year = {2016}
}

@BOOK{dieck_19,
  title = {Augmented Reality and Virtual Reality - The Power of AR and VR for
	Business},
  publisher = {Springer},
  year = {2019},
  editor = {{Tom Dieck, Claudia} and {Jung, Timothy}}
}

@BOOK{dieck_18,
  title = {Augmented Reality and Virtual Reality - Empowering Human, Place and
	Business},
  publisher = {Springer},
  year = {2018},
  editor = {{Jung, Timothy} and {Tom Dieck, Claudia}}
}

@Electronic{vrGit,
  author       = {Manfred Brill},
  title        = {{VRDemos}},
  url          = {\url{https://github.com/VRLAB-HSKL/VRDemos}},
  note         = {Version vom Sommerersemester 2022},
  organization = {Hochschule Kaiserslautern},
  howpublished = {\url{https://github.com/VRLAB-HSKL/VRDemos}},
}

@Electronic{sdl,
  author = {SDL},
  title  = {Simple DirectMedia Layer},
  url    = {https://www.libsdl.org/index.php},
  note   = {Zuletzt gesehen am 6. September 2019},
}

@Electronic{openxr,
  author       = {{OpenXR Working Group}},
  title        = {Unifying Reality},
  url          = {\url{https://www.khronos.org/openxr}},
  note         = {Zuletzt gesehen am 22. August 2022},
  organization = {Khronos Group},
  howpublished = {\url{https://www.khronos.org/openxr/}},
}

@Electronic{vrpnsite,
  author       = {Taylor, Russell},
  title        = {Virtual Reality Peripheral Network - Official Repo},
  url          = {\url{https://github.com/vrpn/vrpn/wiki}},
  note         = {Zuletzt gesehen: 10. Februar 2021},
  howpublished = {\url{https://github.com/vrpn/vrpn/wiki}},
}

@Online{cardboard_guidelines,
  author       = {{Google VR}},
  date         = {2020},
  title        = {Designing for Google Cardboard},
  url          = {\url{https://arvr.google.com/intl/de\_de/cardboard/manufacturers/}},
  note         = {Zuletzt gesehen am 11. Mai 2020},
  howpublished = {\url{https://arvr.google.com/intl/de\_de/cardboard/manufacturers/}},
}

@Online{cardboard_github,
  author       = {{Google VR}},
  date         = {2020},
  title        = {Cardboard SDK},
  url          = {\url{https://github.com/googlevr/cardboard}},
  note         = {Zuletzt gesehen am 11. Mai 2020},
  howpublished = {\url{https://github.com/googlevr/cardboard}},
}

@Online{cardboard_bausatz,
  author       = {{Google VR}},
  date         = {2020},
  title        = {Jetzt bis du dran!},
  url          = {\url{https://arvr.google.com/intl/de\_de/cardboard/manufacturers/}},
  note         = {Zuletzt gesehen am 11. Mai 2020},
  howpublished = {\url{https://arvr.google.com/intl/de\_de/cardboard/manufacturers/}},
}

@Online{cardboard_unity,
  author       = {{Google VR}},
  date         = {2020},
  title        = {Google VR SDK for Unity},
  url          = {\url{https://github.com/googlevr/cardboard}},
  note         = {Zuletzt gesehen am 11. Mai 2020},
  howpublished = {\url{https://github.com/googlevr/cardboard}},
}

@Article{muhanna_15,
  author       = {{Muhanna, Muhanna}},
  date         = {2015},
  journaltitle = {Journal of King Saud Univesity - Computer and Information Sciences},
  title        = {Virtual Reality and the CAVE: Taxonomy, Interaction Challenges and Research Directions},
  doi          = {http://dx.doi.org/10.1016/j.jksuci.2014.03.023},
  number       = {27},
  pages        = {344-361},
  abstract     = {One of the main goals of virtual reality is to provide immersive environments that take
participants away from the real life into a virtual one. Many investigators have been interested in
bringing new technologies, devices, and applications to facilitate this goal. Few, however, have
focused on the specific human–computer interaction aspects of such environments. In this article
we present our literature review of virtual reality and the Cave Automated Virtual Environment
(CAVE). In particular, the article begins by providing a brief overview of the evolution of virtual
reality. In addition, key elements of a virtual reality system are presented along with a proposed
taxonomy that categorizes such systems from the perspective of technologies used and the mental
immersion level found in these systems. Moreover, a detailed overview of the CAVE is presented in
terms of its characteristics, uses, and mainly, the interaction styles inside it. Insights of the interaction
challenges and research directions of investigating interaction with virtual reality systems in
general and the CAVE in particular are thoroughly discussed as well.},
}

@Book{grasnick_20,
  author    = {{Grasnick, Armin}},
  title     = {Grundlagen der virtuellen Realität},
  publisher = {Springer Vieweg},
  subtitle  = {Von der Entdeckung der Perspektive bis zur VR-Brille},
}

@Book{doerner:19,
  author    = {{D"orner, Ralf} and {Broll, Wolfgang} and {Grimm, Paul} and {Jung, Bernhard}},
  title     = {Virtual und Augmented Reality (AR/VR)},
  edition   = {2.},
  publisher = {Springer Vieweg},
  subtitle  = {Grundlagen und Methoden der Virtuellen und Augmentierten Realität},
  year      = {2019},
}

@InProceedings{langbehn_19,
  author     = {{Langbehn, Eike} and {Husung, Malte}},
  booktitle  = {Mensch und Computer 2019},
  title      = {Of Portals and Orbs: An Evaluation of Scene Transition Techniques for Virtual Reality},
  doi        = {https://doi.org/10.1145/3340764.3340779},
  eventdate  = {2019},
  eventtitle = {Mensch und Computer},
  location   = {Hamburg},
}

@InProceedings{wilson_16,
  author     = {{Wilson, Preston} and {Kalescky, William} and {MacLaughlin, Ansel} and {Williams, Betsy}},
  booktitle  = {VRCAI 16},
  year       = {2016},
  title      = {VR Locomotion: Walking > Walking in Place - Arm Swinging},
  doi        = {http://dx.doi.org/10.1145/3013971.3014010},
  eventdate  = {2016},
  eventtitle = {VRCAI},
  pages      = {243--249},
}

@Article{boletsis_19,
  author       = {{Boletsis, Costas} and {Cedergren, Jarl Erik}},
  Year         = {2019},
  journal = {Advances in Human-Computer Interaction},
  title        = {VR Locomotion in the New Era of Virtual Reality: An Empirical Comparison of Prevalent Techniques},
  doi          = {https://doi.org/10.1155/2019/7420781},
}

@InProceedings{ferracani_16,
  author       = {{Ferracani, Andrea} and {Pezzatini, Daniele} and {Bianchini, Jacopo} and {Biscini, Gianmarco} and {Del Bimo, Alberto}},
  booktitle    = {Proceedings of the 1st International Workshop on Multimedia Alternate Realities - {AltMM} {\textquotesingle}16},
  title        = {Locomotion by Natural Gestures for Immersive Virtual Environments},
  doi          = {10.1145/2983298.2983307},
  location     = {Amsterdam},
  organization = {ACM},
  publisher    = {{ACM} Press},
  year         = {2016},
}

@InProceedings{steinicke_18,
  author       = {{Langbehn, Eike} and {Lubos, Paul} and {Steinicke, Frank}},
  booktitle    = {Proceedings of ACM Virtual Reality International Conference (VRIC 18)},
  title        = {Evaluation of Locomotion Techniques for Room-Scale {VR}},
  doi          = {10.1145/3234253.3234291},
  location     = {Laval},
  organization = {ACM},
  publisher    = {{ACM} Press},
  subtitle     = {Joystick, Teleportation, and Redirected Walking},
  year         = {2018},
}

@Article{boletsis_17,
  author    = {Costas Boletsis},
  title     = {The New Era of Virtual Reality Locomotion: A Systematic Literature Review of Techniques and a Proposed Typology},
  doi       = {10.3390/mti1040024},
  number    = {4},
  pages     = {24},
  volume    = {1},
  journal   = {Multimodal Technologies and Interaction},
  publisher = {{MDPI} {AG}},
  year      = {2017},
}

@Report{schwartz_15,
  author      = {{Hayton, Sascha} and {Schwartz, Patrick}},
  date        = {2015},
  institution = {Hochschule Kaiserslautern},
  title       = {VR-Applikationen mit Unity3D},
  type        = {techreport},
  titleaddon  = {Projektarbeit Masterstudiengang Informatik},
  version     = {Wintersemester 14/15},
  year        = {2015},
}

@Book{bowman_17,
  author       = {{LaViola, Joseph} and {Kruijff, Ernst} and {McMahan, Ryan} and {Bowman, Doug} and {Poupyrev, Ivan}},
  date         = {2017},
  title        = {3D User Interfaces},
  edition      = {2.},
  isbn         = {978-0134034324},
  mainsubtitle = {Theory and Practice},
  pagetotal    = {624},
  publisher    = {Addison Wesley},
  subtitle     = {Theory and Practice},
  ean          = {9780134034324},
  keywords     = {AR, VR, Interfaces, HCI},
  year         = {2017},
}

@Electronic{vrpngit,
  author       = {{Taylor, Russell}},
  title        = {{V}{R}{P}{N}},
  url          = {\url{https://github.com/vrpn/vrpn}},
  note         = {Zuletzt gesehen: 10. Februar 2021},
  howpublished = {\url{https://github.com/vrpn/vrpn}},
}

@Electronic{vrgeeks,
  author       = {{VR Geeks}},
  title        = {Tutorial - Use {V}{R}{P}{N}},
  url          = {\url{http://www.vrgeeks.org/vrpn/tutorial---use-vrpn}},
  note         = {Zuletzt gesehen: 10. Februar 2021},
  howpublished = {\url{http://www.vrgeeks.org/vrpn/tutorial---use-vrpn}},
}

@Electronic{wiiuse11,
  author       = {Ryan Pavlik},
  title        = {WiiUse - Compatiblity and Testing History},
  url          = {\url{https://github.com/wiiuse/wiiuse/wiki}},
  note         = {Zuletzt gesehen: 10. Februar 2021},
  howpublished = {\url{https://github.com/wiiuse/wiiuse/wiki}},
}

@Electronic{faast,
  author       = {{Suma, Evan}},
  title        = {Flexible Action and Articulated Skeleton Toolkit (FAAST)},
  url          = {\url{https://ict.usc.edu/prototypes/faast/}},
  note         = {Zuletzt gesehen: 10. Februar 2021},
  howpublished = {\url{https://ict.usc.edu/prototypes/faast/}},
}

@Book{brillbender_06,
  author    = {{Bender, Michael} and {Brill, Manfred}},
  date      = {2006},
  title     = {Computergrafik - Ein anwendungsorientiertes Lehrbuch},
  publisher = {Hanser-Verlag},
}

@Electronic{openvr,
  author       = {ValveSoftware},
  title        = {OpenVR API Documentation},
  url          = {\url{https://github.com/ValveSoftware/openvr/wiki/API-Documentation}},
  note         = {Zuletzt gesehen. 12. Februar 2021},
  organization = {Valve},
  howpublished = {\url{https://github.com/ValveSoftware/openvr/wiki/API-Documentation}},
}

@Electronic{godot,
  author       = {Godot},
  title        = {The game engine you waited for},
  url          = {\url{https://godotengine.org/}},
  note         = {Zuletzt gesehen: 22. Dezember 2021},
  howpublished = {\url{https://godotengine.org/}},
}

@Electronic{webxr_export,
  author       = {MozillaReality},
  title        = {Unity WebXR Exporter},
  url          = {\url{https://github.com/MozillaReality/unity-webxr-export}},
  note         = {Zuletzt gesehen: 16. Februar 2021},
  howpublished = {\url{https://github.com/MozillaReality/unity-webxr-export}},
}

@Electronic{msxr,
  author       = {Microsoft},
  title        = {Mixed Reality-Dokumentation},
  url          = {\url{https://docs.microsoft.com/de-de/windows/mixed-reality/}},
  note         = {Zuletzt gesehen: 16. Februar 2021},
  howpublished = {\url{https://docs.microsoft.com/de-de/windows/mixed-reality/}},
}

@Electronic{msxr_samples,
  author       = {Microsoft},
  title        = {OpenXR Samples for Mixed Reality Developers},
  url          = {\url{https://github.com/microsoft/OpenXR-MixedReality}},
  note         = {Zuletzt gesehen: 18. Februar 2021},
  howpublished = {\url{https://github.com/microsoft/OpenXR-MixedReality}},
}

@Online{vrlab,
  author       = {Manfred Brill},
  title        = {{VRLAB HSKL}},
  url          = {\url{https://github.com/VRLAB-HSKL}},
  note         = {Version vom Wintersemester 2021/22},
  organization = {Hochschule Kaiserslautern},
  howpublished = {\url{https://github.com/VRLAB-HSKL}},
}

@Book{ia:18,
  title     = {Immersive Analytics},
  doi       = {https://doi.org/10.1007/978-3-030-01388-2},
  editor    = {Kim Marriott and Falk Schreiber and Tim Dwyer and Karsten Klein and Nathalie Henry Riche and Takayuki Itoh and Wolfgang Stuerzlinger and Bruce H. Thomas},
  publisher = {Springer International Publishing},
  year      = {2018},
}

@InReference{brill_21,
  author    = {Brill, Manfred},
  booktitle = {Staatslexikon Recht Wirtschaft - Gesellschaft},
  date      = {2021},
  title     = {Virtuelle Realit\"at},
  edition   = {8.},
  editor    = {Oberreuter, Heinrich},
  isbn      = {978-3-451-37515-6},
  pages     = {1511-1514},
  publisher = {Herder},
  volume    = {5},
}

@InProceedings{steed_19,
  author    = {{Abtahi, Parastoo} and {Gonzalez Franco}, Mar and {Ofek, Eyal} and {Steed, Anthony}},
  booktitle = {CHI Conference on Human Factors in Computing Systems Proceedings (CHI 2019)},
  title     = {I'm a Giant: Walking in Large Virtual Environments at High Speed Gains},
  publisher = {ACM},
  url       = {https://www.microsoft.com/en-us/research/publication/im-a-giant-walking-in-large-virtual-environments-at-high-speed-gains-2/},
  abstract  = {Advances in tracking technology and wireless headsets enable walking as a means of locomotion in Virtual Reality. When exploring virtual environments larger than room-scale, it is often desirable to increase users' perceived walking speed, for which we investigate three methods. (1) Ground-Level Scaling increases users' avatar size, allowing them to walk farther. (2) Eye-Level Scaling enables users to walk through a World in Miniature, while maintaining a street-level view. (3) Seven-League Boots amplifies users' movements along their walking path. We conduct a study comparing these methods and find that users feel most embodied using Ground-Level Scaling and consequently increase their stride length. Using Seven-League Boots, unlike the other two methods, diminishes positional accuracy at high gains, and users modify their walking behavior to compensate for the lack of control. We conclude with a discussion on each technique's strength and weaknesses and the types of situation they might be appropriate for.},
  month     = {May},
  year      = {2019},
}

@InProceedings{yang_19,
  author       = {{Yang, Junrui} and {Holz, Christian} and {Ofek, Eyal} and {Wilson, Andrew}},
  booktitle    = {User Interface Software and Technology (UIST) 2019},
  date         = {2019},
  title        = {DreamWalker: Substituting Real-World Walking Experiences with a Virtual Reality},
  organization = {ACM},
  url          = {https://www.microsoft.com/en-us/research/publication/dreamwalker-substituting-real-world-walking-experiences-with-a-virtual-reality/},
  abstract     = {We explore a future in which people spend considerably more time in virtual reality, even during moments when they walk between locations in the real world. In this paper, we present DreamWalker, a VR system that enables such real world walking while users explore and stay fully immersed inside large virtual environments in a headset. Provided with a real-world destination, DreamWalker ﬁnds a similar path in a pre-authored VR environment and guides the user while real walking the virtual world. To keep the user from colliding with objects and people in the real-world, DreamWalker’s tracking system fuses GPS locations, inside-out tracking, and RGBD frames to 1) continuously and accurately position the user in the real world, 2) sense walkable paths and obstacles in real time, and 3) represent paths through a dynamically changing scene in VR to redirect the user towards the chosen destination. We demonstrate DreamWalker’s versatility by enabling users to walk three paths across the large Microsoft campus while enjoying pre-authored VR worlds, supplemented with a variety of obstacle avoidance and redirection techniques. In our evaluation, 8 participants walked across campus along a 15-minute route, experiencing a virtual Manhattan that was full of animated cars, people, and other objects.},
  month        = {October},
  year         = {2019},
}

@InProceedings{cheng_19,
  author    = {{Lung{-}Pan Cheng} and {Eyal Ofek} and {Holz, Christian} and {Wilson, Andrew}},
  booktitle = {{IEEE} Conference on Virtual Reality and 3D User Interfaces, {VR} 2019, Osaka, Japan, March 23-27, 2019},
  date      = {2019},
  title     = {VRoamer: Generating On-The-Fly {VR} Experiences While Walking inside Large, Unknown Real-World Building Environments},
  doi       = {10.1109/VR.2019.8798074},
  pages     = {359--366},
  publisher = {{IEEE}},
  url       = {https://doi.org/10.1109/VR.2019.8798074},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/conf/vr/ChengOHW19.bib},
  timestamp = {Sun, 25 Oct 2020 23:08:58 +0100},
  year      = {2019},
}

@InProceedings{cheng_21,
  author    = {Jen{-}Hao Cheng and Yi Chen and Ting{-}Yi Chang and Hsu{-}En Lin and Po{-}Yao Cosmos Wang and Lung{-}Pan Cheng},
  booktitle = {{IEEE} Virtual Reality and 3D User Interfaces, {VR} 2021, Lisbon, Portugal, March 27 - April 1, 2021},
  title     = {Impossible Staircase: Vertically Real Walking in an Infinite Virtual Tower},
  doi       = {10.1109/VR50410.2021.00025},
  pages     = {50--56},
  publisher = {{IEEE}},
  url       = {https://doi.org/10.1109/VR50410.2021.00025},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/conf/vr/ChengCCLWC21.bib},
  timestamp = {Mon, 17 May 2021 16:02:36 +0200},
  year      = {2021},
}

@InProceedings{kranz_14,
  author    = {M\"{o}ller, Andreas and Kranz, Matthias and Diewald, Stefan and Roalter, Luis and Huitl, Robert and Stockinger, Tobias and Koelle, Marion and Lindemann, Patrick A.},
  booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  title     = {Experimental Evaluation of User Interfaces for Visual Indoor Navigation},
  doi       = {10.1145/2556288.2557003},
  isbn      = {9781450324731},
  location  = {Toronto, Ontario, Canada},
  pages     = {3607–3616},
  publisher = {Association for Computing Machinery},
  series    = {CHI '14},
  url       = {https://doi.org/10.1145/2556288.2557003},
  abstract  = {Mobile location recognition by capturing images of the environment (visual localization) is a promising technique for indoor navigation in arbitrary surroundings. However, it has barely been investigated so far how the user interface (UI) can cope with the challenges of the vision-based localization technique, such as varying quality of the query images. We implemented a novel UI for visual localization, consisting of Virtual Reality (VR) and Augmented Reality (AR) views that actively communicate and ensure localization accuracy. If necessary, the system encourages the user to point the smartphone at distinctive regions to improve localization quality. We evaluated the UI in a experimental navigation task with a prototype, informed by initial evaluation results using design mockups. We found that VR can contribute to efficient and effective indoor navigation even at unreliable location and orientation accuracy. We discuss identified challenges and share lessons learned as recommendations for future work.},
  address   = {New York, NY, USA},
  keywords  = {augmented reality, mobile interaction, visual localization, indoor navigation, virtual reality},
  numpages  = {10},
  year      = {2014},
}

@InProceedings{grosjean_12,
  author    = {{Wonner, Jonathan} and {Grosjean, J{\'{e}}r{\^{o}}me} and {Capobianco, Antonio} and {Bechmann, Dominique}},
  booktitle = {The 18th {ACM} Symposium on Virtual Reality Software and Technology, {VRST} 2012, Toronto, ON, Canada - December 10-12, 2012},
  title     = {Starfish: a selection technique for dense virtual environments},
  doi       = {10.1145/2407336.2407356},
  editor    = {Mark Green and Wolfgang Stuerzlinger and Marc Erich Latoschik and Bill Kapralos},
  pages     = {101--104},
  publisher = {{ACM}},
  url       = {https://doi.org/10.1145/2407336.2407356},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/conf/vrst/WonnerGCB12.bib},
  timestamp = {Thu, 29 Nov 2018 12:50:42 +0100},
  year      = {2012},
}

@InProceedings{grosjean_02,
  author    = {{Grosjean, Jerome} and {Burkhardt, Jean-Marie} and {Coquillart, Sabine} and {Richard, Paul}},
  booktitle = {Proceedings of the 4th IEEE International Conference on Multimodal Interfaces},
  title     = {Evaluation of the Command and Control Cube},
  doi       = {10.1109/ICMI.2002.1167041},
  isbn      = {0769518346},
  pages     = {473},
  publisher = {IEEE Computer Society},
  series    = {ICMI '02},
  url       = {https://doi.org/10.1109/ICMI.2002.1167041},
  abstract  = {Application control in virtual environments (VE) is still an open field of research. The Command and Control Cube (C3) developed by Grosjean et al. is a quick access menu forthe VE configuration called workbench (a large screen displaying stereoscopic images). The C3 presents two modes, one with the graphical display of the cubic structure associated to the C3 and a blind mode for expert users, with no feedback. In this paper we conduct formal tests of the C3 under four different conditions: the visual mode with the graphical display, the blind mode with no feedback and two additional conditions enhancing the expert blind mode: a tactile mode with the tactile feedback of a Cyberglove and a sound mode with a standard audio device. Results show that the addition of sound and tactil feedback is more disturbing to the users than the blind mode. The visual mode performs the best although the blind mode achieves some promising results.},
  address   = {USA},
  year      = {2002},
}

@InProceedings{grosjean_01,
  author    = {{Grosjean, Jerome} and {Coquillart, Sabine}},
  booktitle = {Eurographics Workshop on Virtual Environments},
  title     = {{Command and Control Cube : a Shortcut Paradigm for Virtual Environments}},
  doi       = {10.2312/EGVE/EGVE01/001-012},
  editor    = {B. Froehlich and J. Deisinger and H.-J. Bullinger},
  publisher = {The Eurographics Association},
  year      = {2001},
}

@InProceedings{wim_95,
  author    = {Stoakley, Richard and Conway, Matthew and Pausch, Randy},
  booktitle = {Proceedings of CHI95},
  date      = {1995},
  title     = {Virtual reality on a WIM: Interactive worlds in miniature},
  pages     = {265-272},
  publisher = {ACM},
}

@Article{bowman_06,
  author  = {{Wingrave, Chadwick} and {Haciahmetoglu, Yonca} and {Bowman, Doug}},
  title   = {Overcoming World in Miniature Limitations by a Scaled and Scrolling WIM},
  pages   = {11-16},
  journal = {3D User Interfaces (3DUI'06)},
  year    = {2006},
}

@InProceedings{trueba_08,
  author = {Ram{\'o}n Trueba and And{\'u}jar, Carlos and},
  date   = {2008},
  title  = {Dynamic worlds in miniature},
  year   = {2008},
}

@InProceedings{englmeier_21,
  author    = {{Englmeier, David} and {Sajko, Wanja} and {Butz, Andreas}},
  booktitle = {2021 IEEE Virtual Reality and 3D User Interfaces (VR)},
  date      = {2021},
  title     = {Spherical World in Miniature: Exploring the Tiny Planets Metaphor for Discrete Locomotion in Virtual Reality},
  doi       = {10.1109/VR50410.2021.00057},
  pages     = {345-352},
  year      = {2021},
}

@Article{trueba_10,
  author  = {Ram{\'o}n Trueba and And{\'u}jar, Carlos and Argelaguet, Ferran},
  title   = {World-in-Miniature Interaction for Complex Virtual Environments},
  pages   = {1-14},
  volume  = {1},
  journal = {Int. J. Creative Interfaces Comput. Graph.},
  year    = {2010},
}

@InProceedings{englmeier_20,
  author    = {{Englmeier, David} and {Fan, Fan} and {Butz, Andreas}},
  booktitle = {2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
  date      = {2020},
  title     = {Rock or Roll – Locomotion Techniques with a Handheld Spherical Device in Virtual Reality},
  doi       = {10.1109/ISMAR50242.2020.00089},
  pages     = {618-626},
  publisher = {IEEE},
  abstract  = {We investigate the use of a handheld spherical object as a controller for locomotion in VR. Rotating the object controls avatar movement in two different ways: As a zero order controller, it is continuously rotated to the target position as if rolling a ball on the floor. As a first order controller, it is tilted like a joystick to determine the direction and speed of movement. We describe how our prototype was built from low-cost commercially available hardware and discuss our design decisions. Then we evaluate both locomotion techniques in a user study (N=20) and compare them to established methods using handheld VR controllers. Our prototype matched and in some cases outperformed these methods regarding task time and accuracy. All results were obtained without any usage instructions, indicating easy learnability. Some of our insights may transfer to interaction with other naturally shaped objects in VR experiences.},
  issn      = {1554-7868},
  month     = {Nov},
  year      = {2020},
}

@Article{dachselt_07,
  author   = {{Dachselt, Raimund} and Anett {H"ubner, Anett}},
  title    = {Three-dimensional menus: A survey and taxonomy},
  doi      = {https://doi.org/10.1016/j.cag.2006.09.006},
  issn     = {0097-8493},
  number   = {1},
  pages    = {53-65},
  url      = {https://www.sciencedirect.com/science/article/pii/S0097849306001853},
  volume   = {31},
  abstract = {Various interaction techniques have been developed in the field of virtual and augmented reality. Whereas techniques for object selection, manipulation, travel, and wayfinding have already been covered in existing taxonomies in some detail, application control techniques have not yet been sufficiently considered. However, they are needed by almost every mixed reality application, e.g. for choosing from alternative objects or options. For this purpose a great variety of distinct three-dimensional (3D) menu selection techniques is available. This paper surveys existing 3D menus from the corpus of literature and classifies them according to various criteria. The taxonomy introduced here assists developers of interactive 3D applications to better evaluate their options when choosing, optimizing, and implementing a 3D menu technique. Since the taxonomy spans the design space for 3D menu solutions, it also aids researchers in identifying opportunities to improve or create novel virtual menu techniques.},
  journal  = {Computers & Graphics},
  keywords = {Virtual reality, Desktop VR, Augmented reality, 3D user interfaces, 3D widgets, Interaction techniques},
  year     = {2007},
}

@Article{gebhardt_13,
  author  = {{Gebhardt, Sascha} and {Pick, Sebastian} and {Leithold, Franziska} and {Hentschel, Bernd} and {Kuhlen, Torsten}},
  title   = {Extended Pie Menus for Immersive Virtual Environments},
  date    = {2013},
  doi     = {10.1109/TVCG.2013.31},
  number  = {4},
  pages   = {644-651},
  volume  = {19},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  year    = {2013},
}

@InProceedings{bechmann_05,
  author    = {{Gerber, Dominique} and {Bechmann, Dominique}},
  booktitle = {IEEE Proceedings. VR 2005. Virtual Reality},
  date      = {2005},
  title     = {The spin menu: a menu system for virtual environments},
  doi       = {10.1109/VR.2005.1492790},
  pages     = {271-272},
  year      = {2005},
}

@InProceedings{pausch_97,
  author    = {{Pausch, Randy} and {Proffitt, Dennis} and {Williams, George}},
  booktitle = {Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques},
  date      = {1997},
  title     = {Quantifying Immersion in Virtual Reality},
  doi       = {10.1145/258734.258744},
  isbn      = {0897918967},
  pages     = {13–18},
  publisher = {ACM Press/Addison-Wesley Publishing Co.},
  series    = {SIGGRAPH '97},
  url       = {https://doi.org/10.1145/258734.258744},
  address   = {USA},
  numpages  = {6},
  year      = {1997},
}

@InProceedings{feiner_03,
  author    = {{Feiner, Steven} and {Olwal, Alex}},
  booktitle = {Conference Supplement of UIST ’03 (ACM Symposium on User Interface Software and Technology)},
  date      = {2003},
  title     = {The Flexible Pointer: An Interaction Technique for Augmented and Virtual Reality},
}

@InProceedings{poupyrev_96,
  author    = {{Poupyrev, Ivan} and {Billinghurst, Mark} and {Weghorst, Suzanne} and {Ichikawa, Tadao}},
  booktitle = {Proceedings of the 9th Annual ACM Symposium on User Interface Software and Technology},
  date      = {1996},
  title     = {The Go-Go Interaction Technique: Non-Linear Mapping for Direct Manipulation in VR},
  doi       = {10.1145/237091.237102},
  isbn      = {0897917987},
  location  = {Seattle, Washington, USA},
  pages     = {79–80},
  publisher = {Association for Computing Machinery},
  series    = {UIST '96},
  keywords  = {virtual reality, user interface metaphor, 3D user interface},
  numpages  = {2},
  year      = {1996},
}

@Article{park_19,
  author       = {{Ryu, Kunhee} and {Lee, Joong{-}Jae} and {Park, Jung{-}Min}},
  journaltitle = {Journal on Multimodal User Interfaces},
  title        = {{GG} Interaction: a gaze-grasp pose interaction for 3D virtual object selection},
  doi          = {10.1007/s12193-019-00305-y},
  number       = {4},
  pages        = {383--393},
  volume       = {13},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  biburl       = {https://dblp.org/rec/journals/jmui/RyuLP19.bib},
  journal      = {J. Multimodal User Interfaces},
  timestamp    = {Fri, 31 Jan 2020 21:31:53 +0100},
  year         = {2019},
}

@InProceedings{bulk_20,
  author    = {Bulk, Jendrik AND Paelke, Volker},
  booktitle = {GI VR / AR Workshop},
  title     = {Ein Baukasten zur Evaluation von VR Navigations- und Bewegungtechniken für die Lehre},
  doi       = {10.18420/vrar2020_20},
  editor    = {Weyers, Benjamin AND Lürig, Christoph AND Zielasko, Daniel},
  publisher = {Gesellschaft für Informatik e.V.},
  year      = {2020},
}

@Book{fuchs_11,
  author    = {{Fuchs, Philippe} and {Moreau, Guillaume} and {Guitton, Pascal}},
  date      = {2011},
  title     = {Virtual Reality: Concepts and Technologies},
  isbn      = {978-0203802953},
  pagetotal = {432},
  publisher = {CRC Press},
  url       = {https://www.ebook.de/de/product/21128642/virtual_reality_concepts_and_technologies.html},
  ean       = {9780203802953},
  year      = {2011},
}

@Article{kerres_20,
  author  = {{Mulders, Miriam} and {Buchner, Josef} and {Kerres, Michael}},
  title   = {A Framework for the Use of Immersive Virtual Reality in Learning Environmentsk},
  doi     = {https://doi.org/10.3991/ijet.v15i24.16615},
  number  = {24},
  pages   = {208-223},
  volume  = {15},
  journal = {International Journal of Emerging Technlogies in Learning},
  year    = {2020},
}

@InProceedings{belotti_02,
  author    = {Bellotti, Victoria and Back, Maribeth and Edwards, W. Keith and Grinter, Rebecca E. and Henderson, Austin and Lopes, Cristina},
  booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  title     = {Making Sense of Sensing Systems: Five Questions for Designers and Researchers},
  doi       = {10.1145/503376.503450},
  isbn      = {1581134533},
  location  = {Minneapolis, Minnesota, USA},
  pages     = {415–422},
  publisher = {Association for Computing Machinery},
  series    = {CHI '02},
  url       = {https://doi.org/10.1145/503376.503450},
  abstract  = {This paper borrows ideas from social science to inform the design of novel "sensing" user-interfaces for computing technology. Specifically, we present five design challenges inspired by analysis of human-human communication that are mundanely addressed by traditional graphical user interface designs (GUIs). Although classic GUI conventions allow us to finesse these questions, recent research into innovative interaction techniques such as 'Ubiquitous Computing' and 'Tangible Interfaces' has begun to expose the interaction challenges and problems they pose. By making them explicit we open a discourse on how an approach similar to that used by social scientists in studying human-human interaction might inform the design of novel interaction mechanisms that can be used to handle human-computer communication accomplishments},
  address   = {New York, NY, USA},
  keywords  = {design framework, social science, ubiquitous computing, human-machine communication, sensing input},
  numpages  = {8},
  year      = {2002},
}

@InProceedings{steinicke_21a,
  author    = {Hertel, Julia and Karaosmanoglu, Sukran and Schmidt, Susanne and Bräker, Julia and Semmann, Martin and Steinicke, Frank},
  booktitle = {Proceedings of the International Symposium on Mixed and Augmenting Reality (ISMAR)},
  title     = {A Taxonomy of Interaction Techniques for Immersive Augmented Reality based on an Iterative Literature Review},
  url       = {http://basilic.informatik.uni-hamburg.de/Publications/2021/HKSBSS21},
  year      = {2021},
}

@InProceedings{steinicke_21,
  author    = {Schmelter, Thereza and Hernandi, Levente and Störmer, Marc Aurel and Steinicke, Frank and Hildebrand, Kristian},
  booktitle = {Proceedings of the ACM on Computer Graphics and Interactive Techniques (i3D)},
  title     = {Interaction-Based Redirected Walking},
  url       = {http://basilic.informatik.uni-hamburg.de/Publications/2021/ HSSH21},
  year      = {2021},
}

@InProceedings{steinicke_18a,
  author    = {Langbehn, Eike and Lubos, Paul and Steinicke, Frank},
  booktitle = {Proceedings of the Virtual Reality International Conference (VRIC)},
  date      = {2018},
  title     = {Evaluation of Locomotion Techniques for Room-Scale VR: Joystick, Teleportation, and Redirected Walking},
  url       = {http://basilic.informatik.uni-hamburg.de/Publications/2018/LLS18a},
  year      = {2018},
}

@InProceedings{steinicke_18b,
  author    = {Neves Coelho, Daniel and Schmidt, Susanne and Steinicke, Frank},
  booktitle = {Proceedings of the GI Workshop on Virtual and Augmented Reality (GI VR/AR)},
  date      = {2018},
  title     = {Kategorisierung und Evaluierung von Transitionen für CAVE Umgebungen},
  url       = {http://basilic.informatik.uni-hamburg.de/Publications/2018/NSS18a},
  year      = {2018},
}

@Article{dunk_10,
  author       = {Dunk, Andrew and Haffegee, Adrian and Alexandrov, Vassil},
  date         = {2010},
  journaltitle = {Procedia Computer Science},
  title        = {Selection methods for interactive creation and management of objects in 3D immersive environments},
  doi          = {10.1016/j.procs.2010.04.294},
  number       = {1},
  pages        = {2609---2617},
  volume       = {1},
  journal      = {Procedia CS},
  month        = {05},
  publisher    = {Elsevier {BV}},
  year         = {2010},
}

@InProceedings{mohan_18,
  author    = {{Mohan, Pallavi} and {Goh, Wooi Boon} and {Fu, Chi-Wing} and {Yeung, Sai-Kit}},
  booktitle = {2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)},
  title     = {DualGaze: Addressing the Midas Touch Problem in Gaze Mediated VR Interaction},
  doi       = {10.1109/ISMAR-Adjunct.2018.00039},
  pages     = {79-84},
  year      = {2018},
}

@Article{bowman_12,
  author     = {{Bowman, Doug} and {McMahan, Ryan} and {Ragan, Eric}},
  title      = {Questioning Naturalism in 3D User Interfaces},
  doi        = {10.1145/2330667.2330687},
  number     = {9},
  pages      = {78–88},
  volume     = {55},
  abstract   = {3D UIs are uniquely able to achieve superior interaction fidelity, and this naturalism can be a huge advantage.},
  address    = {New York, NY, USA},
  issue_date = {September 2012},
  journal    = {Commun. ACM},
  month      = {sep},
  numpages   = {11},
  publisher  = {Association for Computing Machinery},
  year       = {2012},
}

@InProceedings{doerner_21,
  author    = {{Horst, Robin and D"orner, Ralf}},
  booktitle = {Eurographics 2021 - Education Papers},
  title     = {{Conveying Firsthand Experience: The Circuit Parcours Technique for Efficient and Engaging Teaching in Courses about Virtual Reality and Augmented Reality}},
  doi       = {10.2312/eged.20211002},
  editor    = {Sousa Santos, Beatriz and Domik, Gitta},
  isbn      = {978-3-03868-132-8},
  publisher = {The Eurographics Association},
  issn      = {1017-4656},
  year      = {2021},
}

@InProceedings{kanani_17,
  author    = {Kanani, Mohsen and Al-Jabir, Yousif and Al-Ghanim, Salem and Halabi, Osama},
  booktitle = {2017 6th International Conference on Information and Communication Technology and Accessibility (ICTA)},
  title     = {Enhanced redirected walking algorithm},
  doi       = {10.1109/ICTA.2017.8336063},
  pages     = {1-2},
  year      = {2017},
}

@InProceedings{steinice_ordw_21,
  author    = {Li, Yi-Jun and Wang, Miao and Steinicke, Frank and Zhao, Qinping},
  booktitle = {2021 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
  title     = {OpenRDW: A Redirected Walking Library and Benchmark with Multi-User, Learning-based Functionalities and State-of-the-art Algorithms},
  doi       = {10.1109/ISMAR52148.2021.00016},
  pages     = {21-30},
  year      = {2021},
}

@Article{straus_rdw_20,
  author  = {Strauss, Ryan R. and Ramanujan, Raghuram and Becker, Andrew and Peck, Tabitha C.},
  date    = {2020},
  title   = {A Steering Algorithm for Redirected Walking Using Reinforcement Learning},
  doi     = {10.1109/TVCG.2020.2973060},
  number  = {5},
  pages   = {1955-1963},
  volume  = {26},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  year    = {2020},
}

@InProceedings{suma_rdw_14,
  author    = {Azmandian, Mahdi and Yahata, Rhys and Bolas, Mark and Suma, Evan},
  booktitle = {2014 IEEE Virtual Reality (VR)},
  title     = {An enhanced steering algorithm for redirected walking in virtual environments},
  doi       = {10.1109/VR.2014.6802053},
  pages     = {65-66},
  year      = {2014},
}

@InProceedings{suma_rdw_16,
  author    = {Azmandian, Mahdi and Grechkin, Timofey and Bolas, Mark and Suma, Evan},
  booktitle = {2016 IEEE 2nd Workshop on Everyday Virtual Reality (WEVR)},
  title     = {The redirected walking toolkit: a unified development platform for exploring large virtual environments},
  doi       = {10.1109/WEVR.2016.7859537},
  pages     = {9-14},
  year      = {2016},
}

@InProceedings{suma_rdw_14,
  author    = {Azmandian, Mahdi and Yahata, Rhys and Bolas, Mark and Suma, Evan},
  booktitle = {2014 IEEE Virtual Reality (VR)},
  title     = {An enhanced steering algorithm for redirected walking in virtual environments},
  doi       = {10.1109/VR.2014.6802053},
  pages     = {65-66},
  year      = {2014},
}

@Article{williams_21,
  author    = {Williams, Niall L and Bera, Aniket and Manocha, Dinesh},
  title     = {Redirected {W}alking in {S}tatic and {D}ynamic {S}cenes {U}sing {V}isibility {P}olygons},
  journal   = {IEEE Transactions on Visualization \& Computer Graphics},
  publisher = {IEEE Computer Society},
  year      = {2021},
}

@InProceedings{openrdw_21,
  author    = {Li, Yi-Jun and Wang, Miao and Steinicke, Frank and Zhao, Qinping},
  booktitle = {2021 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
  title     = {OpenRDW: A Redirected Walking Library and Benchmark with Multi-User, Learning-based Functionalities and State-of-the-art Algorithms},
  doi       = {10.1109/ISMAR52148.2021.00016},
  pages     = {21-30},
  year      = {2021},
}

@InProceedings{Steinicke_21,
  author    = {Chen, Ze-Yin and Li, Yi-Jun and Wang, Miao and Steinicke, Frank and Zhao, Qinping},
  booktitle = {2021 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
  title     = {A Reinforcement Learning Approach to Redirected Walking with Passive Haptic Feedback},
  doi       = {10.1109/ISMAR52148.2021.00033},
  pages     = {184-192},
  year      = {2021},
}

@InProceedings{bowman_22,
  author    = {Lisle, Lee and Lu, Feiyu and Davari, Shakiba and Tahmid, Ibrahim Asadullah and Giovannelli, Alexander and Llo, Cory and Pavanatto, Leonardo and Zhang, Lei and Schlueter, Luke and Bowman, Doug A.},
  booktitle = {2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
  title     = {Clean the Ocean: An Immersive VR Experience Proposing New Modifications to Go-Go and WiM Techniques},
  doi       = {10.1109/VRW55335.2022.00311},
  pages     = {920-921},
  year      = {2022},
}

@InProceedings{hawes_22,
  author    = {{Hawes, Dan} and {Arya, Ali}},
  booktitle = {2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
  title     = {VR-based Context Priming to Increase Student Engagement and Academic Performance},
  doi       = {10.1109/VRW55335.2022.00196},
  pages     = {690-691},
  year      = {2022},
}

@InProceedings{belleman_22,
  author    = {Chen, Jolly and Belleman, Robert G.},
  booktitle = {2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
  title     = {MeasVRe: Measurement Tools for Unity VR Applications},
  doi       = {10.1109/VRW55335.2022.00231},
  pages     = {760-761},
  year      = {2022},
}

@InProceedings{wang_22,
  author    = {Wang, Lili and Liu, Yi and Liu, Xiaolong and Wu, Jian},
  booktitle = {2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
  title     = {Automatic Virtual Portals Placement for Efficient VR Navigation},
  doi       = {10.1109/VRW55335.2022.00165},
  pages     = {628-629},
  year      = {2022},
}

@InProceedings{choi_22,
  author    = {Choi, Kristine and Crumb, Garrett and Li, Richard and Natarrajan, Raahul and Tong, Patrick and Molvig, Ole and Bodenheimer, Bobby},
  booktitle = {2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
  title     = {Experience Orchestra: Manipulating Musical Instruments in VR},
  doi       = {10.1109/VRW55335.2022.00310},
  pages     = {918-919},
  year      = {2022},
}

@InProceedings{belter_22,
  author    = {Belter, Meike and Lukosch, Heide},
  booktitle = {2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
  title     = {Towards a Virtual Reality Math Game for Learning In Schools - A User Study},
  doi       = {10.1109/VRW55335.2022.00255},
  pages     = {808-809},
  year      = {2022},
}

@InProceedings{steed_22,
  author    = {Ganapathi, Priya and Thiel, Felix J. and Swapp, David and Steed, Anthony},
  booktitle = {2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
  title     = {Head in the Clouds - Floating Locomotion in Virtual Reality},
  doi       = {10.1109/VRW55335.2022.00185},
  pages     = {668-669},
  year      = {2022},
}

@InProceedings{wu_22,
  author    = {Martinez, Esteban Segarra and Wu, Annie S. and McMahan, Ryan P.},
  booktitle = {2022 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
  title     = {Research Trends in Virtual Reality Locomotion Techniques},
  doi       = {10.1109/VR51125.2022.00046},
  pages     = {270-280},
  year      = {2022},
}

@InProceedings{fujita_22,
  author    = {Hoshikawa, Yukai and Fujita, Kazuyuki and Takashima, Kazuki and Fjeld, Morten and Kitamura, Yoshifumi},
  booktitle = {2022 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
  title     = {RedirectedDoors: Redirection While Opening Doors in Virtual Reality},
  doi       = {10.1109/VR51125.2022.00066},
  pages     = {464-473},
  year      = {2022},
}

@InProceedings{han_22,
  author    = {Han, Jihae and Moere, Andrew Vande and Simeone, Adalberto L.},
  booktitle = {2022 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
  title     = {Foldable Spaces: An Overt Redirection Approach for Natural Walking in Virtual Reality},
  doi       = {10.1109/VR51125.2022.00035},
  pages     = {167-175},
  year      = {2022},
}

@InProceedings{paris_22,
  author    = {Paris, Richard A. and Buck, Lauren E. and McNamara, Timothy P. and Bodenheimer, Bobby},
  booktitle = {2022 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
  title     = {Evaluating the Impact of Limited Physical Space on the Navigation Performance of Two Locomotion Methods in Immersive Virtual Environments},
  doi       = {10.1109/VR51125.2022.00104},
  pages     = {821-831},
  year      = {2022},
}

@InProceedings{bowman_22a,
  author    = {Davari, Shakiba and Lu, Feiyu and Bowman, Doug A.},
  booktitle = {2022 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
  title     = {Validating the Benefits of Glanceable and Context-Aware Augmented Reality for Everyday Information Access Tasks},
  doi       = {10.1109/VR51125.2022.00063},
  pages     = {436-444},
  year      = {2022},
}

@InProceedings{kunz_22,
  author    = {Hirt, Christian and Kompis, Yves and Holz, Christian and Kunz, Andreas},
  booktitle = {2022 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
  title     = {The Chaotic Behavior of Redirection – Revisiting Simulations in Redirected Walking},
  doi       = {10.1109/VR51125.2022.00072},
  pages     = {524-533},
  year      = {2022},
}

@InProceedings{schier_22,
  author    = {Schier, Florian and Chandran, Krishnan and McGinity, Matthew},
  booktitle = {2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
  title     = {TeachInVR: A virtual reality classroom for remote education},
  doi       = {10.1109/VRW55335.2022.00064},
  pages     = {283-286},
  year      = {2022},
}

@InProceedings{bowman_20,
  author    = {Lu, Feiyu and Davari, Shakiba and Lisle, Lee and Li, Yuan and Bowman, Doug A.},
  booktitle = {2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
  title     = {Glanceable AR: Evaluating Information Access Methods for Head-Worn Augmented Reality},
  doi       = {10.1109/VR46266.2020.00113},
  pages     = {930-939},
  year      = {2020},
}

@InProceedings{Hagedorn_07,
  author       = {John G. Hagedorn and Joy P. Dunkers and Steven G.$\mathsemicolon$ Satterfield and Adele P. Peskin and John T. Kelso and Judith E. Terrill},
  title        = {Measurement tools for the immersive visualization environment: Steps toward the virtual laboratory},
  doi          = {doi:10.6028/jres.112.019},
  number       = {5},
  pages        = {257},
  publisher    = {National Institute of Standards and Technology ({NIST})},
  volume       = {112},
  journaltitle = {Journal of Research of the National Institute of Standards and Technology},
}

@InProceedings{preim_17,
  author    = {Patrick Saalfeld and Johannes Patzschke and Bernhard Preim},
  booktitle = {Mensch und Computer},
  title     = {An Immersive System for Exploring and Measuring Medical Image Data},
  pages     = {73-82},
  pubstate  = {published},
  url       = {https://www.vismd.de/wp-content/uploads/legacy/saalfeld_2017_mc_a.pdf, PDF Download
https://www.youtube.com/watch?v=MM6gK0hVks8, YouTube},
  tppubtype = {inproceedings},
  year      = {2017},
}

@InProceedings{benford_93,
  author    = {Steve Benford and Lennart E. Fahl{\'{e}}n},
  booktitle = {Third European Conference on Computer Supported Cooperative Work, ECSCW'93, Milano, Italy, September 13-17, 1993, Proceedings},
  title     = {A Spatial Model of Interaction in Large Virtual Environments},
  pages     = {107},
  publisher = {Kluwer Academic Publishers},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/conf/ecscw/BenfordF93.bib},
  timestamp = {Wed, 20 Jun 2018 17:29:45 +0200},
  year      = {1993},
}

@PhdThesis{bozgeyikliy_16,
  author      = {{Bozgeyikliy, Evren}},
  date        = {2016},
  institution = {University of South Florida},
  title       = {Locomotion in Virtual Reality for Room ScaleTracked Areas},
}

@InProceedings{park_14,
  author = {Jaemoon Jung and Hanjun Park and Dongwook Hwang and Minseok Son and Donghyun Beck},
  title  = {A Review on Interaction Techniques in Virtual Environments},
  year   = {2014},
}

@PhdThesis{lubos_18,
  author      = {{Lubos, Paul}},
  date        = {2018},
  institution = {Universität Hamburg},
  title       = {Supernatural and Comfortable User Interfacesfor Basic 3D Interaction Tasks},
}

@Article{jacob_91,
  author     = {Jacob, Robert J. K.},
  date       = {1991},
  title      = {The Use of Eye Movements in Human-Computer Interaction Techniques: What You Look at is What You Get},
  doi        = {10.1145/123078.128728},
  issn       = {1046-8188},
  number     = {2},
  pages      = {152–169},
  url        = {https://doi.org/10.1145/123078.128728},
  volume     = {9},
  address    = {New York, NY, USA},
  issue_date = {April 1991},
  journal    = {ACM Trans. Inf. Syst.},
  keywords   = {eye movements, UIMS, input, human-computer interaction, eye tracking, state transition diagram},
  month      = {apr},
  numpages   = {18},
  publisher  = {Association for Computing Machinery},
  year       = {1991},
}

@InProceedings{williams_18,
  author    = {{Coomer, Noah} and {Bullard, Sadler} and {Clinton, William} and {Williams, Betsy}},
  booktitle = {Proceedings of the 15th ACM Symposium on Applied Perception},
  date      = {2018-08},
  title     = {Evaluating the effects of four VR locomotion methods: joystick, arm-cycling, point-tugging, and teleporting},
  doi       = {10.1145/3225153.3225175},
  pages     = {1-8},
  publisher = {ACM},
  month     = {08},
  year      = {2018},
}

@InProceedings{zenner_21,
  author    = {{Zenner, Andr\'{e}} and {Kriegler, Hannah Maria} and {Kr\"{u}ger, Antonio}},
  booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
  title     = {HaRT - The Virtual Reality Hand Redirection Toolkit},
  doi       = {10.1145/3411763.3451814},
  location  = {Yokohama, Japan},
  publisher = {Association for Computing Machinery},
  series    = {CHI EA '21},
  url       = {https://doi.org/10.1145/3411763.3451814},
  abstract  = {Past research has proposed various hand redirection techniques for virtual reality (VR). Such techniques modify a user’s hand movements and have been successfully used to enhance haptics and 3D user interfaces. Up to now, however, no unified framework exists that implements previously proposed techniques such as body warping, world warping, and hybrid methods. In this work, we present the Virtual Reality Hand Redirection Toolkit (HaRT), an open-source framework developed for the Unity engine. The toolkit aims to support both novice and expert VR researchers and practitioners in implementing and evaluating hand redirection techniques. It provides implementations of popular redirection algorithms and exposes a modular class hierarchy for easy integration of new approaches. Moreover, simulation, logging, and visualization features allow users of the toolkit to analyze hand redirection setups with minimal technical effort. We present the architecture of the toolkit along with the results of a qualitative expert study.},
  articleno = {387},
  keywords  = {redirected touching, hand redirection, reach redirection, haptic retargeting, toolkit},
  numpages  = {7},
  year      = {2021},
}

@Electronic{anthropometrie,
  author = {Wikipedia},
  title  = {Anthropometrie},
  url    = {\url{https://de.wikipedia.org/wiki/Anthropometrie}},
  note   = {Zuletzt gesehen: 28. Juni 2022},
}

@Book{linowes:20,
  author    = {{Linowes, Jonathan}},
  title     = {Unity 2020 Virtual Reality Projects - Learn VR development by building immersive application and games with Unity 2019.4 and later versions},
  publisher = {Packt Publishing},
  year      = {2020},
}

@Electronic{humanHeight,
  author = {Wikipedia},
  title  = {Average human height by country},
  url    = {\url{https://en.wikipedia.org/wiki/Average\_human\_height\_by\_country}},
  note   = {Zuletzt gesehen: 27. August 2022},
}

@Book{platon_staat,
  author    = {Platon},
  date      = {1828},
  title     = {Der Staat},
  editor    = {{Schleiermacher, F.}},
  publisher = {G. Reimer},
  address   = {Berlin},
}

@Book{coleridge_04,
  author    = {{Coleridge, Samuel Taylor}},
  title     = {Biographia Literaria},
  doi       = {10.2307/3713748},
  publisher = {Project Gutenberg},
  url       = {\url{https://www.gutenberg.org/ebooks/6081}},
}

@Misc{matrix,
  author = {{Wachowsky, Lana} and {Wachowsky, Lilly}},
  date   = {1999},
  title  = {Matrix},
}

@Article{lanier_89,
  author     = {{Conn, Coco} and {Lanier, Jaron} and {Minsky, Margaret} and {Fisher, Scott} and {Druin, Allison}},
  title      = {Virtual Environments and Interactivity: Windows to the Future},
  doi        = {10.1145/77277.77278},
  issn       = {0097-8930},
  number     = {5},
  pages      = {7–18},
  url        = {https://doi.org/10.1145/77277.77278},
  volume     = {23},
  abstract   = {I really apologize. I promised everyone I would come out wearing the data suit, but it just slipped my mind and I never got around to it. Actually Marvin Minsky was saying that the thing to do would be to come out with nothing on because that would be the perfect interface to the computer. So I kind of shunned the whole thing off at that point.We just heard Nicholas Negroponte ask us -- "how do we communicate with computers?" Well, that's why this panel is here today. We'll be discussing virtual environments and interactivity with some of the people who have been doing a lot of work in this field. I was interviewing a lot of people last night at the parties about virtual environments and I realized that everyone has their own idea of what their virtual environment will be. Some want to interact more, others less. Some want little people running around on the screen bringing them all sorts of messages or images. We'll be hearing about a lot of different types of interactivity on our panel today.I'd like to point out that Margaret's slide should also include the MIT Media Lab as well as UNC.I'm going to show some tapes and do some talking later on so I'd like start of by introducing Jaron Lanier. He's the guy with the dreadlocks you've seen at the Silicon Graphics booth. He has an amazing collection of musical instruments from all over the world and when he plays them, he transports you to other times and other places. He's a designer of programming languages and he started VPL, the company that brought you the glove, Jaron.},
  address    = {New York, NY, USA},
  issue_date = {Dec. 1989},
  journal    = {SIGGRAPH Comput. Graph.},
  month      = {jul},
  numpages   = {12},
  publisher  = {Association for Computing Machinery},
  year       = {1989},
}

@Electronic{oxygen480,
  author   = {{Oxygen Team, KDE}},
  title    = {Oxygen480-apps-preferences-desktop-gaming.svg},
  url      = {\url{https://commons.wikimedia.org/w/index.php?curid=18609993}},
  note     = {LGPL},
  pubstate = {LGPL},
  keywords = {Wiki Commons LGPL},
}

@Electronic{openxrsdkrepo,
  author       = {{hronos Group}},
  title        = {OpenXR SDK Project},
  url          = {\url{https://github.com/KhronosGroup/OpenXR-SDK}},
  note         = {Zuletzt gesehen am 14. Dezember 2022},
  organization = {Khronos Group},
  howpublished = {\url{https://github.com/KhronosGroup/OpenXR-SDK/}},
}

@Electronic{openxrloader,
  author       = {{Khronos Group}},
  title        = {OpenXR Loader - Design and Operation},
  url          = {\url{https://registry.khronos.org/OpenXR/specs/1.0/loader.html}},
  note         = {Zuletzt gesehen am 14. Dezember 2022},
  organization = {Khronos Group},
  howpublished = {\url{https://registry.khronos.org/OpenXR/specs/1.0/loader.html/}},
}

@Electronic{openxrdocsrepo,
  author       = {{hronos Group}},
  title        = {OpenXR API documentation Project},
  url          = {\url{https://github.com/KhronosGroup/OpenXR-Docs}},
  note         = {Zuletzt gesehen am 14. Dezember 2022},
  organization = {Khronos Group},
  howpublished = {\url{https://github.com/KhronosGroup/OpenXR-Docs/}},
}

@Electronic{openxapirepo,
  author       = {{Khronos Group}},
  title        = {Khronos OpenXR Registry},
  url          = {\url{https://registry.khronos.org/OpenXR/}},
  note         = {Zuletzt gesehen am 14. Dezember 2022},
  organization = {Khronos Group},
  howpublished = {\url{https://registry.khronos.org/OpenXR/}},
}

@Book{woods_04,
  author    = {{Woods, Andrew J.} and {Merrit, John O.} and {Benton, Stephen A.} and {Bolas, Mark T.}},
  date      = {2004},
  title     = {Stereoscopic Displays and virtual Reality Systems XI},
  isbn      = {0819451940},
  location  = {San José},
  pagetotal = {526},
  publisher = {SPIE},
  subtitle  = {19-22 January 2004, San Jose, California, USA},
}

@InProceedings{dodgson_04,
  author    = {{Dodgson, Neil A.}},
  booktitle = {Stereoscopy Displays and virtual Reality Systems XI},
  date      = {2004},
  title     = {Variation and extrema of human interpupillary distance},
  location  = {San José, California, U.S.A.},
  pages     = {36--46},
}

@InProceedings{zielasko_17,
  author    = {{Zielasko, Daniel} and {Weyers, Benjamin} and {Bellgardt, Martin} and {Pick, Sebastian} and {Meibner, Alexander} and {Vierjahn, Tom} and {Kuhlen, Torsten W.}},
  booktitle = {2017 IEEE 3rd Workshop on Everyday Virtual Reality (WEVR)},
  title     = {Remain seated: towards fully-immersive desktop VR},
  doi       = {10.1109/WEVR.2017.7957707},
  pages     = {1-6},
  year      = {2017},
}

@Article{blom_14,
  author     = {{Blom, Kristopher J.} and {Beckhaus, Steffi}},
  date       = {2014},
  title      = {The Design Space of Dynamic Interactive Virtual Environments},
  doi        = {10.1007/s10055-013-0232-y},
  issn       = {1359-4338},
  number     = {2},
  pages      = {101–116},
  url        = {https://doi.org/10.1007/s10055-013-0232-y},
  volume     = {18},
  abstract   = {Virtual environments have become a key component of many fields and the critical component of virtual reality applications. Due to their virtual nature, they can accommodate an infinite number of possibilities. A theoretical work is presented, which decomposes those innumerous possibilities into concepts to help clarify the vast design space and provide insights into future applied research. We propose that what makes environments interesting and engaging is having worlds that are both active and reactive. This article explores the manifestations of those actions and reactions in what we term: dynamic components and interactions. We term worlds containing these dynamic interactive virtual environments (DIVE). An analysis of each component time was performed, with the purpose of providing a theoretical understanding of the respective design spaces. Initially, we collected the myriad possibilities of each component, e.g., the possible kinds of interactions. We point to examples throughout the field to ground and explain concepts presented. We then categorized of each area into taxonomies. The result of the analyses provides insights into the design space of virtual environments, exposes several avenues of research that are yet underexplored, and provides better understandings of ways in which DIVE creation can be supported.},
  address    = {Berlin, Heidelberg},
  issue_date = {June 2014},
  journal    = {Virtual Real.},
  keywords   = {3D user interaction, VR systems, Virtual environments, Dynamic interactive VEs},
  month      = {Juni},
  numpages   = {16},
  publisher  = {Springer-Verlag},
  year       = {2014},
}

@Electronic{suspension,
  author  = {{Wulff, Hans J"urgen}},
  title   = {Lexikon der Filmbegriffe: Suspension of Disbelief},
  url     = {\url{https://filmlexikon.uni-kiel.de/doku.php/s:suspensionofdisbelief-4370}},
  note    = {Zuletzt gesehen: 04. Janaur 2023},
  urldate = {2023-01-04},
  owner   = {Lexikon der Filmbegriffe},
}

@Manual{vdc_21,
  author    = {{Macedo, Vitor}},
  date      = {2021},
  editor    = {Virtual Dimension Center (VDC) Fellbach},
  title     = {Head-Mounted displays - Messung räumlicher Präzision bei VR-Trackingsystemen},
  publisher = {VDC Fellbach},
  pubstate  = {Online},
  url       = {\url{https://www.vdc-fellbach.de/fileadmin/user\_upload/Applikationszentrum\_VAR\_-\_Bericht\_\_04\_2\_-\_AP2\_-\_Werkstattbericht\_\_02\_-\_Messung\_VR-Tracking-Praezision\_-\_Update.pdf}},
  version   = {2},
}

@InProceedings{brill_22,
  author    = {{Brill, Manfred} and {S"arota, Benedict}},
  booktitle = {Proceedings of DELFI Workshops 2022},
  title     = {Proceedings of DELFI Workshops 2022 - Preface},
  editor    = {Mandausch, Martin AND Henning, Peter A.},
  pages     = {69-76},
  publisher = {Gesellschaft für Informatik e.V.},
  address   = {Bonn},
  year      = {2022},
}

@TechReport{ILRN_21,
  author      = {{Lee, Mark} and {Georgieva, Maya} and {Alexander, Bryan} and {Craig, Emory} and {Richter, Jonathan}},
  date        = {2021},
  institution = {Immersive Learning Research Network},
  title       = {State of XR and Immersive Learning 2021},
  isrn        = {978-1-7348995-1-1},
  location    = {Walnut, CA},
  type        = {techreport},
  year        = {2021},
}

@Article{kruger_95,
  author       = {Kruger, W. and Bohn, C.-A. and Frohlich, B. and Schuth, H. and Strauss, W. and Wesche, G.},
  date         = {1995-07},
  journaltitle = {Computer},
  title        = {The Responsive Workbench: a virtual work environment},
  doi          = {10.1109/2.391040},
  number       = {7},
  pages        = {42-48},
  volume       = {28},
  journal      = {Computer},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  year         = {1995},
}

@InProceedings{cheng_17,
  author    = {Cheng, Lung-Pan and Ofek, Eyal and Holz, Christian and Benko, Hrvoje and Wilson, Andrew D.},
  booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
  title     = {Sparse Haptic Proxy: Touch Feedback in Virtual Environments Using a General Passive Prop},
  doi       = {10.1145/3025453.3025753},
  isbn      = {9781450346559},
  location  = {Denver, Colorado, USA},
  pages     = {3718–3728},
  publisher = {Association for Computing Machinery},
  series    = {CHI '17},
  url       = {https://doi.org/10.1145/3025453.3025753},
  abstract  = {We propose a class of passive haptics that we call Sparse Haptic Proxy: a set of geometric primitives that simulate touch feedback in elaborate virtual reality scenes. Unlike previous passive haptics that replicate the virtual environment in physical space, a Sparse Haptic Proxy simulates a scene's detailed geometry by redirecting the user's hand to a matching primitive of the proxy. To bridge the divergence of the scene from the proxy, we augment an existing Haptic Retargeting technique with an on-the-fly target remapping: We predict users' intentions during interaction in the virtual space by analyzing their gaze and hand motions, and consequently redirect their hand to a matching part of the proxy. We conducted three user studies on haptic retargeting technique and implemented a system from three main results: 1) The maximum angle participants found acceptable for retargeting their hand is 40°, with an average rating of 4.6 out of 5. 2) Tracking participants' eye gaze reliably predicts their touch intentions (97.5\%), even while simultaneously manipulating the user's hand-eye coordination for retargeting. 3) Participants preferred minimized retargeting distances over better-matching surfaces of our Sparse Haptic Proxy when receiving haptic feedback for single-finger touch input. We demonstrate our system with two virtual scenes: a flight cockpit and a room quest game. While their scene geometries differ substantially, both use the same sparse haptic proxy to provide haptic feedback to the user during task completion.},
  address   = {New York, NY, USA},
  keywords  = {perception, passive haptics, virtual reality, retargeting},
  numpages  = {11},
  year      = {2017},
}

@InProceedings{azmandian_16,
  author    = {Azmandian, Mahdi and Hancock, Mark and Benko, Hrvoje and Ofek, Eyal and Wilson, Andrew D.},
  booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
  title     = {Haptic Retargeting: Dynamic Repurposing of Passive Haptics for Enhanced Virtual Reality Experiences},
  doi       = {10.1145/2858036.2858226},
  isbn      = {9781450333627},
  location  = {San Jose, California, USA},
  pages     = {1968–1979},
  publisher = {Association for Computing Machinery},
  series    = {CHI '16},
  url       = {https://doi.org/10.1145/2858036.2858226},
  abstract  = {Manipulating a virtual object with appropriate passive haptic cues provides a satisfying sense of presence in virtual reality. However, scaling such experiences to support multiple virtual objects is a challenge as each one needs to be accompanied with a precisely-located haptic proxy object. We propose a solution that overcomes this limitation by hacking human perception. We have created a framework for repurposing passive haptics, called haptic retargeting, that leverages the dominance of vision when our senses conflict. With haptic retargeting, a single physical prop can provide passive haptics for multiple virtual objects. We introduce three approaches for dynamically aligning physical and virtual objects: world manipulation, body manipulation and a hybrid technique which combines both world and body manipulation. Our study results indicate that all our haptic retargeting techniques improve the sense of presence when compared to typical wand-based 3D control of virtual objects. Furthermore, our hybrid haptic retargeting achieved the highest satisfaction and presence scores while limiting the visible side-effects during interaction.},
  address   = {New York, NY, USA},
  keywords  = {virtual reality, haptics, perception},
  numpages  = {12},
  year      = {2016},
}

@InProceedings{kohli_10,
  author    = {Kohli, Luv},
  booktitle = {2010 IEEE Symposium on 3D User Interfaces (3DUI)},
  title     = {Redirected touching: Warping space to remap passive haptics},
  doi       = {10.1109/3DUI.2010.5444703},
  pages     = {129-130},
  abstract  = {There is an increasing interest in deployable virtual military training systems. Haptic feedback for these training systems can enable users to interact more naturally with the training environment, but is difficult to deploy. Passive haptic feedback is very compelling, but it is also inflexible. Changes made to virtual objects can require time-consuming changes to their physical passive-haptic counterparts. This poster explores the possibility of mapping many differently shaped virtual objects onto one physical object by warping virtual space and exploiting the dominance of the visual system. A first implementation that maps different virtual objects onto dynamically captured physical geometry is presented, and potential applications to deployable military trainers are discussed.},
  month     = {March},
  year      = {2010},
}

@InProceedings{ragan_19,
  author    = {Stebbins, Travis and Ragan, Eric D.},
  booktitle = {2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
  title     = {Redirecting View Rotation in Immersive Movies with Washout Filters},
  doi       = {10.1109/VR.2019.8797994},
  pages     = {377-385},
  abstract  = {Immersive movies take advantage of virtual reality (VR) to bring new opportunities for storytelling that allow users to naturally turn their heads and bodies to view a 3D virtual world and follow the story in a surrounding space. However, while many designers often assume scenarios where viewers stand and are free to physically turn without constraints, this excludes many commonly desired usage settings where the user may wish to remain seated, such as the use of VR while relaxing on the couch or passing the time during a flight. For such situations, large amounts of physical turning may be uncomfortable due to neck strain or awkward twisting. Our research investigates a technique that automatically rotates the virtual scene to help redirect the viewer's physical rotation while viewing immersive narrative experiences. By slowly rotating the virtual content, viewers are encouraged to gradually turn physically to align their head positions to a more comfortable straight-ahead viewing direction in seated situations where physical turning is not ideal. We present our study of technique design and an evaluation of how the redirection approach affects user comfort, sickness, the amount of physical rotation, and likelihood of viewers noticing the rotational adjustments. Evaluation results show the rotation technique was effective at significantly reducing the amount of physical turning while watching immersive videos, and only 39% of participants noticed the automated rotation when the technique rotated at a speed of 3 degrees per second.},
  issn      = {2642-5254},
  month     = {March},
  year      = {2019},
}

@InProceedings{ragan_20,
  author    = {Esmaeili, Shaghayegh and Benda, Brett and Ragan, Eric D.},
  booktitle = {2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
  title     = {Detection of Scaled Hand Interactions in Virtual Reality: The Effects of Motion Direction and Task Complexity},
  doi       = {10.1109/VR46266.2020.00066},
  pages     = {453-462},
  abstract  = {In virtual reality (VR), natural physical hand interaction allows users to interact with virtual content using physical gestures. While the most straightforward use of tracked hand motion maintains a one-to-one mapping between the physical and virtual world, some cases might benefit from changing this mapping through scaled or redirected interactions that modify the mapping between user’s physical movements and the magnitude of corresponding virtual movements. However, large deviations in interaction fidelity may potentially provide distractions or a loss of perceived realism. Therefore, it is important to know the extent to which remapping techniques can be applied to scaled interactions in VR without users detecting the difference. In this paper, we extend prior research on redirected hand techniques by investigating user perception of scaled hand movements and estimating detection thresholds for different types of hand motion in VR. We conducted two experiments with a two-alternative forced-choice (2AFC) design to estimate the detection thresholds of remapped interaction. The first experiment tested the perception of motion scaling for simple hand movements, and the second experiment involved more complex reaching motions in a cognitively demanding game scenario. We present estimated detection thresholds for scale values that can be applied to virtual hand movements without users noticing the difference. Our findings show that detection thresholds differ significantly based on the type of hand movement (horizontal, vertical, and depth).},
  issn      = {2642-5254},
  month     = {March},
  year      = {2020},
}

@InProceedings{ragan_20a,
  author    = {Benda, Brett and Esmaeili, Shaghayegh and Ragan, Eric D.},
  booktitle = {2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
  title     = {Determining Detection Thresholds for Fixed Positional Offsets for Virtual Hand Remapping in Virtual Reality},
  doi       = {10.1109/ISMAR50242.2020.00050},
  pages     = {269-278},
  abstract  = {Virtual reality commonly makes use of tracked hand interactions for user input. Interaction techniques sometimes alter the mapping between the real and virtual coordinate systems to modify interaction possibilities. This paper studies fixed positional offsets applied to the location of the virtual hand. We present a controlled experiment in which users' hands were subject to fixed positional offsets of varying magnitudes while completing target-touching tasks. The study provides estimations for detection thresholds for positional hand offsets in six directions relative to the real-world location of the hand and provides evidence performance using offset virtual hands can vary based on offset parameters. Significant differences in offset detection were identified based on offset direction, indicating that positional adjustments made to virtual hands should consider directionality when limiting techniques rather than just a constant value. Hand offsets kept within the threshold value resulted in comparable performance to unmodified hand registration, while offsets beyond the threshold resulted in larger completion times.},
  issn      = {1554-7868},
  month     = {Nov},
  year      = {2020},
}

@InProceedings{ragan_17,
  author    = {Sargunam, Shyam Prathish and Moghadam, Kasra Rahimi and Suhail, Mohamed and Ragan, Eric D.},
  booktitle = {2017 IEEE Virtual Reality (VR)},
  title     = {Guided head rotation and amplified head rotation: Evaluating semi-natural travel and viewing techniques in virtual reality},
  doi       = {10.1109/VR.2017.7892227},
  pages     = {19-28},
  abstract  = {Traditionally in virtual reality systems, head tracking is used in head-mounted displays (HMDs) to allow users to control viewing using 360-degree head and body rotations. Our research explores interaction considerations that enable semi-natural methods of view control that will work for seated use of virtual reality with HMDs when physically turning all the way around is not ideal, such as when sitting on a couch or at a desk. We investigate the use of amplified head rotations so physically turning in a comfortable range can allow viewing of a 360-degree virtual range. Additionally, to avoid situations where the user's neck is turned in an uncomfortable position for an extended period, we also use redirection during virtual movement to gradually realign the user's head position back to the neutral, straight-ahead position. We ran a controlled experiment to evaluate guided head rotation and amplified head rotation without realignment during movement, and we compared both to traditional one-to-one head-tracked viewing as a baseline for reference. After a navigation task, overall errors on spatial orientation tasks were relatively low with all techniques, but orientation effects, sickness, and preferences varied depending on participants' 3D gaming habits. Using the guided rotation technique, participants who played 3D games performed better, reported higher preference scores, and demonstrated significantly lower sickness results compared to non-gamers.},
  issn      = {2375-5334},
  month     = {March},
  year      = {2017},
}

@InProceedings{ragan_17a,
  author    = {Suhail, Mohamed and Sargunam, Shyam Prathish and Han, Dustin T. and Ragan, Eric D.},
  booktitle = {2017 IEEE Symposium on 3D User Interfaces (3DUI)},
  title     = {Redirected reach in virtual reality: Enabling natural hand interaction at multiple virtual locations with passive haptics},
  doi       = {10.1109/3DUI.2017.7893363},
  pages     = {245-246},
  abstract  = {In many virtual reality applications, it would be ideal if users could use their physical hands to directly interact with virtual objects while experiencing realistic haptic feedback. While this can be achieved via interaction with tracked physical props that correspond to virtual objects, practical limitations can make it difficult to achieve a physical environment that exactly represents the virtual world, and virtual environments are often much larger than the available tracked physical space. Our approach maps a single physical prop to multiple virtual objects distributed throughout a virtual environment. Additionally, our work explores scenarios using one physical prop to control multiple types of object interactions. We explore considerations that allow physical object manipulation using orientation resetting to physically align the user with a physical prop for interaction. The resetting approach applies a discrete positional and rotational update to the user's location when the user virtually approaches a target for interaction, and the redirected reach approach applies a translational offset to the users virtual hand based on the positional difference of the virtual and physical objects.},
  month     = {March},
  year      = {2017},
}

@InProceedings{ragan_22,
  author    = {You, Christopher and Benda, Brett and Rosenberg, Evan Suma and Ragan, Eric and Lok, Benjamin and Thomas, Jerald},
  booktitle = {2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
  title     = {Strafing Gain: Redirecting Users One Diagonal Step at a Time},
  doi       = {10.1109/ISMAR55827.2022.00077},
  pages     = {603-611},
  abstract  = {Redirected walking can effectively utilize a user’s physical space when traversing larger virtual environments by using virtual self-motion gains for a user’s physical motions. In particular, curvature gain presents unique advantages in redirection but can lead to suboptimal orientations. To prevent this and add additional utility in redirected walking, we formally present strafing gain. Strafing gain seeks to add incremental lateral movements to a user’s position causing the user to walk along a diagonal trajectory while maintaining the original orientation of the user. In a study with 27 participants, we tested 11 values to determine the detection thresholds of strafing gain. The study, which was modeled on prior detection threshold studies, found that strafing gain could successfully redirect participants to walk along a 5.57° diagonal to the right and a 4.68° diagonal to the left. Furthermore, a supplementary study with 10 participants was conducted, verifying that orientation was maintained throughout redirection and validating the obtained detection thresholds. We discuss the implications of these findings and potential ways of improving these quantities in real-world applications.},
  issn      = {1554-7868},
  month     = {Oct},
  year      = {2022},
}

@InProceedings{grossman_06,
  author    = {Grossman, Tovi and Balakrishnan, Ravin},
  booktitle = {Proceedings of the 19th Annual ACM Symposium on User Interface Software and Technology},
  title     = {The Design and Evaluation of Selection Techniques for 3D Volumetric Displays},
  doi       = {10.1145/1166253.1166257},
  isbn      = {1595933131},
  location  = {Montreux, Switzerland},
  pages     = {3–12},
  publisher = {Association for Computing Machinery},
  series    = {UIST '06},
  url       = {https://doi.org/10.1145/1166253.1166257},
  abstract  = {Volumetric displays, which display imagery in true 3D space, are a promising platform for the display and manipulation of 3D data. To fully leverage their capabilities, appropriate user interfaces and interaction techniques must be designed. In this paper, we explore 3D selection techniques for volumetric displays. In a first experiment, we find a ray cursor to be superior to a 3D point cursor in a single target environment. To address the difficulties associated with dense target environments we design four new ray cursor techniques which provide disambiguation mechanisms for multiple intersected targets. Our techniques showed varied success in a second, dense target experiment. One of the new techniques, the depth ray, performed particularly well, significantly reducing movement time, error rate, and input device footprint in comparison to the 3D point cursor.},
  address   = {New York, NY, USA},
  keywords  = {selection, 3D interaction, volumetric displays},
  numpages  = {10},
  year      = {2006},
}

@InProceedings{ihara_23,
  author    = {Ihara, Keiichi and Kawaguchi, Ikkaku},
  booktitle = {Asian HCI Symposium'22},
  title     = {Virtual Object Placement in MR Space Using a 3D Miniature Model of a Room},
  doi       = {10.1145/3516492.3558789},
  isbn      = {9781450392501},
  location  = {New Orleans, LA, USA},
  pages     = {23–29},
  publisher = {Association for Computing Machinery},
  series    = {CHI22},
  url       = {https://doi.org/10.1145/3516492.3558789},
  abstract  = {In this research, we propose a World in Miniature (WIM) -based technique for object placement in MR space. We considered that this would make it possible to freely place objects in 3D space, and to immediately check the position of objects that have been rearranged. In our prototype, we used the mesh of the room provided to represent the occlusion relationship by the MR device to generate a 3D miniature model of the room. We also made it possible to manipulate the virtual objects in the room by manipulating the miniature objects in the miniature model. In order to obtain a guideline for future system design, we conducted an experiment to investigate the characteristics of the manipulation of miniature objects in MR. The results showed that the manipulation of miniature objects in MR is effective in object searching, moving, and reducing physical workload, but that scaling manipulation is difficult. The results also suggest that these effects are affected by the viewing angle and the accuracy of hand tracking of the MR device, and provide guidelines for future system design.},
  address   = {New York, NY, USA},
  keywords  = {3D user interaction, distant object placement, augmented reality},
  numpages  = {7},
  year      = {2023},
}

@InProceedings{ban_22,
  author    = {Ban, Reigo and Matsumoto, Keigo and Narumi, Takuji and Kuzuoka, Hideaki},
  booktitle = {2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
  title     = {Wormholes in VR: Teleporting Hands for Flexible Passive Haptics},
  doi       = {10.1109/ISMAR55827.2022.00093},
  pages     = {748-757},
  year      = {2022},
}

@InProceedings{achibet_15,
  author    = {Achibet, Merwan and Girard, Adrien and Talvas, Anthony and Marchal, Maud and Lécuyer, Anatole},
  booktitle = {2015 IEEE Virtual Reality (VR)},
  title     = {Elastic-Arm: Human-scale passive haptic feedback for augmenting interaction and perception in virtual environments},
  doi       = {10.1109/VR.2015.7223325},
  pages     = {63-68},
  abstract  = {Haptic feedback is known to improve 3D interaction in virtual environments but current haptic interfaces remain complex and tailored to desktop interaction. In this paper, we introduce the “Elastic-Arm”, a novel approach for incorporating haptic feedback in immersive virtual environments in a simple and cost-effective way. The Elastic-Arm is based on a body-mounted elastic armature that links the user's hand to her shoulder. As a result, a progressive resistance force is perceived when extending the arm. This haptic feedback can be incorporated with various 3D interaction techniques and we illustrate the possibilities offered by our system through several use cases based on well-known examples such as the Bubble technique, Redirected Touching and pseudo-haptics. These illustrative use cases provide users with haptic feedback during selection and navigation tasks but they also enhance their perception of the virtual environment. Taken together, these examples suggest that the Elastic-Arm can be transposed in numerous applications and with various 3D interaction metaphors in which a mobile hap-tic feedback can be beneficial. It could also pave the way for the design of new interaction techniques based on “human-scale” egocentric haptic feedback.},
  issn      = {2375-5334},
  month     = {March},
  year      = {2015},
}

@Article{archibet_16,
  author   = {Achibet, Merwan and Girard, Adrien and Marchal, Maud and Lécuyer, Anatole},
  title    = {Leveraging Passive Haptic Feedback in Virtual Environments with the Elastic-Arm Approach},
  doi      = {10.1162/PRES_a_00243},
  issn     = {1054-7460},
  number   = {1},
  pages    = {17-32},
  volume   = {25},
  abstract = {Haptic feedback is known to improve 3D interaction in virtual environments but current haptic interfaces remain complex and tailored to desktop interaction. In this paper, we describe an alternative approach called “Elastic-Arm” for incorporating haptic feedback in immersive virtual environments in a simple and cost-effective way. The Elastic-Arm is based on a body-mounted elastic armature that links the user's hand to the body and generates a progressive egocentric force when extending the arm. A variety of designs can be proposed with multiple links attached to various locations on the body in order to simulate different haptic properties and sensations such as different levels of stiffness, weight lifting, and bimanual interaction. Our passive haptic approach can be combined with various 3D interaction techniques and we illustrate the possibilities offered by the Elastic-Arm through several use cases based on well-known techniques such as the Bubble technique, redirected touching, and pseudo-haptics. A user study was conducted which showed the effectiveness of our pseudo-haptic technique as well as the general appreciation of the Elastic-Arm. We believe that the Elastic-Arm could be used in various VR applications which call for mobile haptic feedback or human-scale haptic sensations.},
  journal  = {Presence},
  month    = {July},
  year     = {2016},
}

@InProceedings{cunningham_22,
  author    = {Ablett, Daniel and Cunningham, Andrew and Lee, Gun A. and Thomas, Bruce H.},
  booktitle = {2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
  title     = {Portal Rendering and Creation Interactions in Virtual Reality},
  doi       = {10.1109/ISMAR55827.2022.00030},
  pages     = {160-168},
  abstract  = {Transformative portals are a novel technique for supporting visualizations and interactions between locations that are not co-located in virtual reality (VR). We are interested in improving upon current portal rendering for VR, and supporting VR users to create new portals quickly and accurately. In this paper, we introduce a new high-level algorithm for rendering transformative portals in VR and present the benefits of our approach. By leveraging single-pass stereo and stencil portal rendering, we developed our algorithm to support multiple portals with “infinite” recursion, while running performant on mobile VR devices. We then benchmarked our performance against other common portal rendering implementations. In addition, we focused our research on VR interactions for handheld portals, in which the initial placement of the portal’s destination is imperative to its effectiveness. In this paper, we present four new portal creation interactions for handheld portals: fishing reel, raycast with fishing reel, marker, and projectile curve. Based on existing research, we also established standard controls for fine-grained portal manipulation. In a user study, we compared and evaluated how well the creation interactions performed and argue that projectile curve is the most suitable general-purpose technique.},
  issn      = {1554-7868},
  month     = {Oct},
  year      = {2022},
}

@Article{mendes_19,
  author   = {Mendes, D. and Caputo, F. M. and Giachetti, A. and Ferreira, A. and Jorge, J.},
  title    = {A Survey on 3D Virtual Object Manipulation: From the Desktop to Immersive Virtual Environments},
  doi      = {https://doi.org/10.1111/cgf.13390},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13390},
  number   = {1},
  pages    = {21-45},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13390},
  volume   = {38},
  abstract = {Abstract Interactions within virtual environments often require manipulating 3D virtual objects. To this end, researchers have endeavoured to find efficient solutions using either traditional input devices or focusing on different input modalities, such as touch and mid-air gestures. Different virtual environments and diverse input modalities present specific issues to control object position, orientation and scaling: traditional mouse input, for example, presents non-trivial challenges because of the need to map between 2D input and 3D actions. While interactive surfaces enable more natural approaches, they still require smart mappings. Mid-air gestures can be exploited to offer natural manipulations mimicking interactions with physical objects. However, these approaches often lack precision and control. All these issues and many others have been addressed in a large body of work. In this article, we survey the state-of-the-art in 3D object manipulation, ranging from traditional desktop approaches to touch and mid-air interfaces, to interact in diverse virtual environments. We propose a new taxonomy to better classify manipulation properties. Using our taxonomy, we discuss the techniques presented in the surveyed literature, highlighting trends, guidelines and open challenges, that can be useful both to future research and to developers of 3D user interfaces.},
  journal  = {Computer Graphics Forum},
  keywords = {3D user interfaces, interaction techniques, virtual object manipulation, H.5.2 Information Interfaces and Presentation: User Interfaces Interaction styles},
  year     = {2019},
}

@InProceedings{liu_22,
  author    = {Liu, Xiaolong and Wang, Lili and Luan, Shuai and Shi, Xuehuai and Liu, Xinda},
  booktitle = {2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
  title     = {Distant Object Manipulation with Adaptive Gains in Virtual Reality},
  doi       = {10.1109/ISMAR55827.2022.00092},
  pages     = {739-747},
  abstract  = {Object Manipulation is a fundamental interaction in virtual reality (VR). The efficiency and accuracy of object manipulation are important to provide immersion to users. We propose a manipulation method with adaptive gains to improve the efficiency and accuracy of object manipulation in VR applications. First, we introduce manipulation gains. We then design an experiment to collect user behavior during manipulation to determine fitting functions for calculating manipulation gain. At last, we design a user study to evaluate the performance of our distant object manipulation method with adaptive gains. The results show that, compared with the state of the art methods, our method has a significant improvement in the completion time, and the manipulation accuracy of the tasks. Moreover, our method significantly increases usability and reduces task load.},
  issn      = {1554-7868},
  month     = {Oct},
  year      = {2022},
}

@InProceedings{yu_22,
  author    = {Yu, Difeng and Zhou, Qiushi and Dingler, Tilman and Velloso, Eduardo and Goncalves, Jorge},
  booktitle = {2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
  title     = {Blending On-Body and Mid-Air Interaction in Virtual Reality},
  doi       = {10.1109/ISMAR55827.2022.00081},
  pages     = {637-646},
  abstract  = {On-body interfaces, which leverage the human body’s surface as an input or output platform, can provide new opportunities for designing VR interaction. However, it remains unclear how on-body interfaces can best support current VR systems that mainly rely on mid-air interaction. We propose BodyOn, a collection of six design patterns that leverage combined on-body and mid-air interfaces to achieve more effective 3D interaction. Specifically, a user may use thumb-on-finger gestures, finger-on-arm gestures, or on-body displays with mid-air input, including hand movement and orientation, to complete an interaction task. To test our design concepts, we implemented example interaction techniques based on BodyOn that can assist users in various 3D interaction tasks. We further conducted an expert evaluation using the techniques as probes to elicit immediate design issues that emerge from the novel combination of on-body and midair interaction. We provide insights that can inspire and inform the design of future 3D user interfaces.},
  issn      = {1554-7868},
  month     = {Oct},
  year      = {2022},
}

@InProceedings{silva_20,
  author    = {Silva, Luca and Valença, Lucas and Gomes, Arlindo and Figueiredo, Lucas and Teichrieb, Veronica},
  booktitle = {2020 19th Brazilian Symposium on Computer Games and Digital Entertainment (SBGames)},
  title     = {GoThrough: a Tool for Creating and Visualizing Impossible 3D Worlds Using Portals},
  doi       = {10.1109/SBGames51465.2020.00023},
  pages     = {97-106},
  abstract  = {Portals are commonly used in video games (e.g., games like Portal, Antichamber, and the classic Asteroids). In this work we introduce GoThrough, a tool that enables users with little to no previous knowledge to add transformative portals to 3D scenes in the Unity game engine. We map the existing literature in portals, both in terms of academic works and web resources, as well as entertainment usages. Then, we introduce an approach for portals to work robustly both in terms of geometry and rendering, and explore common pitfalls (as well as how to handle them). The tool is shown to work in a variety of example scenarios, and has been evaluated quantitatively for performance, providing real-time performance in a variety of scenarios. User tests have also been conducted in order to analyse GoThrough qualitatively. With a SUS score of 87.5, we concluded that GoThrough is intuitive enough to be used by non-experts, making the process of creating impossible 3D worlds much less cumbersome.},
  issn      = {2159-6662},
  month     = {Nov},
  year      = {2020},
}

@InProceedings{gulcu_22,
  author    = {Gülcü, Ali Emre and Atalay, F. Betül},
  booktitle = {2022 7th International Conference on Computer Science and Engineering (UBMK)},
  title     = {Infinite Spaces Using Recursive Portals},
  doi       = {10.1109/UBMK55850.2022.9919479},
  pages     = {332-337},
  abstract  = {One of the strongest aspects of virtual reality (VR) hardware and applications is the immersion it provides to the user. While combination of techniques such as real-walking for locomotion, head movement for gaze direction and hand detection for controls are great for immersive experience; when the real space and the virtual environment does not match, developers must resort to alternative locomotion techniques such as teleportation, controller-assisted movement or in-place walking via external devices. Despite lifting the restrictions on physical spaces, these techniques may need expensive or cumbersome hardware, cause nausea and dizziness on the user or simply diminish the immersion. We propose a portal based environment design method and a modern rendering engine to visualize the created scenes. Our method uses the same physical space by overlapping multiple regions of the virtual environment on top of each other while keeping the affine properties of the scene. The user can walk between different virtual rooms while staying in a limited physical space. We also conduct a user study to compare user experience to state-of-the-art physical-virtual environment mapping method; in which, the users strongly favored our method.},
  issn      = {2521-1641},
  month     = {Sep.},
  year      = {2022},
}

@InProceedings{nam_19,
  author    = {Nam, Jung Who and McCullough, Krista and Tveite, Joshua and Espinosa, Maria Molina and Perry, Charles H. and Wilson, Barry T. and Keefe, Daniel F.},
  booktitle = {2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
  title     = {Worlds-in-Wedges: Combining Worlds-in-Miniature and Portals to Support Comparative Immersive Visualization of Forestry Data},
  doi       = {10.1109/VR.2019.8797871},
  pages     = {747-755},
  abstract  = {Virtual reality (VR) environments are typically designed so users feel present in a single virtual world at a time, but this creates a problem for applications that require visual comparisons (e.g., forest scientists comparing multiple data-driven virtual forests). To address this, we present Worlds-in-Wedges, a 3D user interface and visualization technique that supports comparative immersive visualization by dividing the virtual space surrounding the user into volumetric wedges. There are three visual/interactive levels. The first, worlds-in-context, visualizes high-level relationships between the worlds (e.g., a map for worlds that are related in space). The second level, worlds-in-miniature, is a multi-instance implementation of the World-in-Miniature technique extended to support mutlivari-ate glyph visualization. The third level, worlds-in-wedges, displays multiple large-scale worlds in wedges that act as volumetric portals. The interface supports navigation, selection, and view manipulation. Since the techniques were inspired directly by problems facing forest scientists, the interface was evaluated by building a complete multivariate data visualization of the US Forest Service Forest Inventory and Analysis public dataset. Scientist user feedback and lessons from iterative design are reported.},
  issn      = {2642-5254},
  month     = {March},
  year      = {2019},
}

@InProceedings{pivovar_22,
  author    = {Pivovar, Jarod and DeGuzman, Jasmine and Rosenberg, Evan Suma},
  booktitle = {2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
  title     = {Virtual Reality on a SWIM: Scalable World in Miniature},
  doi       = {10.1109/VRW55335.2022.00307},
  pages     = {912-913},
  abstract  = {The World-in-Miniature (WIM) metaphor is a 3D user interface technique that allows the user to interact with an identical miniature copy of the virtual environment they are in. Users are able to manipulate an object in either the miniature copy or the life-size copy and have that change reflected in the other model. This general model lacks a method to adjust the sizing of the objects in the miniature copy or the view that it displays. As a result, precise movement on objects of a different scale becomes difficult in vast and compact spaces. We propose the Scalable World in Miniature (SWIM) which affords independent scaling and finer control across a spectrum of object sizes. By treating the WIM as an independently scalable volume of interest, users can set specific objects and subsections or the entire environment as their view in the miniature model at a scale to their liking. Only the objects displayed in the WIM can be interacted with, allowing for more natural interactions with objects of different scale factors. The proposed solution of the Scalable World in Miniature (SWIM) provides users an increased flexibility and more intuitive interactions with the WIM system.},
  month     = {March},
  year      = {2022},
}

@InProceedings{bonsch_16,
  author    = {Bonsch, Andrea and Freitag, Sebastian and Kuhlen, Torsten W.},
  booktitle = {2016 IEEE Virtual Reality (VR)},
  title     = {Automatic generation of world in miniatures for realistic architectural immersive virtual environments},
  doi       = {10.1109/VR.2016.7504700},
  pages     = {155-156},
  abstract  = {Orientation and wayfinding in architectural Immersive Virtual Environments (IVEs) are non-trivial, accompanying tasks which generally support the users' main task. World in Miniatures (WIMs) - essentially 3D maps containing a scene replica - are an established approach to gain survey knowledge about the virtual world, as well as information about the user's relation to it. However, for large-scale, information-rich scenes, scaling and occlusion issues result in diminishing returns. Since there typically is a lack of standardized information regarding scene decompositions, presenting the inside of self-contained scene extracts is challenging. Therefore, we present an automatic WIM generation workflow for arbitrary, realistic in- and outdoor IVEs in order to support users with meaningfully selected and scaled extracts of the IVE as well as corresponding context information. Additionally, a 3D user interface is provided to manually manipulate the represented extract.},
  issn      = {2375-5334},
  month     = {March},
  year      = {2016},
}

@InProceedings{butz_21,
  author    = {Englmeier, David and Sajko, Wanja and Butz, Andreas},
  booktitle = {2021 IEEE Virtual Reality and 3D User Interfaces (VR)},
  title     = {Spherical World in Miniature: Exploring the Tiny Planets Metaphor for Discrete Locomotion in Virtual Reality},
  doi       = {10.1109/VR50410.2021.00057},
  pages     = {345-352},
  abstract  = {We explore the concept of a Spherical World in Miniature (SWIM) for discrete locomotion in Virtual Reality (VR). A SWIM wraps a planar WIM around a physically embodied sphere and thereby implements the metaphor of a tangible Tiny Planet that can be rotated and moved, enabling scrolling, scaling, and avatar teleportation. The scaling factor is set according to the sphere's distance from the head-mounted display (HMD), while rotation moves the current viewing window. Teleportation is triggered with a dwell time when looking at the sphere and keeping it still. In a lab study (N=20), we compare our SWIM implementation to a planar WIM with an established VR controller technique using physical buttons. We test both concepts in a navigation task and also investigate the effects of two different screen sizes. Our results show that the SWIM, despite its less direct geometrical transformation, performed superior in most evaluations. It outperformed the planar WIM not only in terms of task completion time (TCT) and accuracy but also in subjective ratings.},
  issn      = {2642-5254},
  month     = {March},
  year      = {2021},
}

@InProceedings{butz_09,
  author    = {Trueba, Ram{\'o}n and Andujar, Carlos and Argelaguet, Ferran},
  booktitle = {Smart Graphics},
  title     = {Complexity and Occlusion Management for the World-in-Miniature Metaphor},
  editor    = {Butz, Andreas and Fisher, Brian and Christie, Marc and Kr{\"u}ger, Antonio and Olivier, Patrick and Ther{\'o}n, Roberto},
  isbn      = {978-3-642-02115-2},
  pages     = {155--166},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {The World in Miniature (WIM) metaphor allows users to interact and travel efficiently in virtual environments. In addition to the first-person perspective offered by typical VR applications, the WIM offers a second dynamic viewpoint through a hand-held miniature copy of the environment. In the original WIM paper the miniature was a scaled down replica of the whole scene, thus limiting its application to simple models being manipulated at a single level of scale. Several WIM extensions have been proposed where the replica shows only a part of the environment. In this paper we present a new approach to handle complexity and occlusion in the WIM. We discuss algorithms for selecting the region of the scene which will be covered by the miniature copy and for handling occlusion from an exocentric viewpoint. We also present the results of a user-study showing that our technique can greatly improve user performance on spatial tasks in densely-occluded scenes.},
  address   = {Berlin, Heidelberg},
  year      = {2009},
}

@InProceedings{truman_20,
  author    = {Truman, Samuel and von Mammen, Sebastian},
  booktitle = {Proceedings of the 15th International Conference on the Foundations of Digital Games},
  title     = {An Integrated Design of World-in-Miniature Navigation in Virtual Reality},
  doi       = {10.1145/3402942.3402994},
  isbn      = {9781450388078},
  location  = {Bugibba, Malta},
  publisher = {Association for Computing Machinery},
  series    = {FDG '20},
  url       = {https://doi.org/10.1145/3402942.3402994},
  abstract  = {Navigation is considered one of the most fundamental challenges in Virtual Reality (VR) and has been extensively researched [11]. The world-in-miniature (WIM) navigation metaphor allows users to travel in large-scale virtual environments (VEs) regardless of available physical space while maintaining a high-level overview of the VE. It relies on a hand-held, scaled-down duplicate of the entire VE, where the user’s current position is displayed, and an interface provided to introduce his/her next movements [17]. There are several extensions to deal with challenges of this navigation technique, e.g. scaling and scrolling [23]. In this work, a WIM is presented that integrates state-of-the-art research insights and incorporates additional features that became apparent during the integration process. These features are needed to improve user interactions and to provide both look-ahead and post-travel feedback. For instance, a novel occlusion handling feature hides the WIM geometry in a rounded space reaching from the user’s hand to his/her forearm. This allows the user to interact with occluded areas of the WIM such as buildings. Further extensions include different visualizations for occlusion handling, an interactive preview screen, post-travel feedback, automatic WIM customization, a unified diegetic UI design concerning WIM and user representation, and an adaptation of widely established gestures to control scaling and scrolling of the WIM. Overall, the presented WIM design integrates and extends state-of-the-art interaction tasks and visualization concepts to overcome open conceptual gaps and to provide a comprehensive practical solution for traveling in VR.},
  address   = {New York, NY, USA},
  articleno = {69},
  keywords  = {navigation, virtual reality, world-in-miniature},
  numpages  = {9},
  year      = {2020},
}

@InProceedings{bowman_06,
  author    = {Wingrave, C.A. and Haciahmetoglu, Y. and Bowman, D.A.},
  booktitle = {3D User Interfaces (3DUI'06)},
  title     = {Overcoming World in Miniature Limitations by a Scaled and Scrolling WIM},
  doi       = {10.1109/VR.2006.106},
  pages     = {11-16},
  abstract  = {The World In Miniature (WIM) technique has effectively allowed users to interact and travel efficiently in Virtual Environments. However, WIM fails to work in worlds with tasks at various levels of scale. Such an example is using the WIM to arrange furniture and then leaving the room to travel the city using the WIM for navigation and wayfinding. To address this problem, scaling and scrolling were added to the WIM to create the Scaled Scrolling World In Miniature (SSWIM). The interface and testbed were iteratively created under expert evaluation and multiple formative user evaluations led to the final design. The WIM and SSWIM were then compared inside three differently sized cities by users who located a sphere and traveled into it to read the label at the sphere’s center. Users were administered two standard psychology tests to account for spatial orientation (Cube Comparison Test) and spatial scanning (Maze Tracing Test) factors. The results show that the SSWIM’s added functionality, and hence complexity, caused no significant hit in user performance and additionally that users were able to use SSWIM effectively after a short instructional period. To better understand the effect of experience, a follow-up experiment was performed showing performance plateaued after ten to fifteen minutes of use.},
  month     = {March},
  year      = {2006},
}

@InProceedings{danyluk_21,
  author    = {Danyluk, Kurtis and Ens, Barrett and Jenny, Bernhard and Willett, Wesley},
  booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  title     = {A Design Space Exploration of Worlds in Miniature},
  doi       = {10.1145/3411764.3445098},
  isbn      = {9781450380966},
  location  = {Yokohama, Japan},
  publisher = {Association for Computing Machinery},
  series    = {CHI '21},
  url       = {https://doi.org/10.1145/3411764.3445098},
  abstract  = {Worlds-in-Miniature (WiMs) are interactive worlds within a world and combine the advantages of an input space, a cartographic map, and an overview+detail interface. They have been used across the extended virtuality spectrum for a variety of applications. Building on an analysis of examples of WiMs from the research literature we contribute a design space for WiMs based on seven design dimensions. Further, we expand upon existing definitions of WiMs to provide a definition that applies across the extended reality spectrum. We identify the design dimensions of size-scope-scale, abstraction, geometry, reference frame, links, multiples, and virtuality. Using our framework we describe existing Worlds-in-Miniature from the research literature and reveal unexplored research areas. Finally, we generate new examples of WiMs using our framework to fill some of these gaps. With our findings, we identify opportunities that can guide future research into WiMs.},
  address   = {New York, NY, USA},
  articleno = {122},
  keywords  = {Meta-Analysis/Literature Survey, Virtual/Augmented Reality},
  numpages  = {15},
  year      = {2021},
}

@Comment{jabref-meta: databaseType:biblatex;}
